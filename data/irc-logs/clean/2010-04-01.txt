[00:03] devinus_ has joined the channel
[00:05] <broofa> Asparagusto: (ping)
[00:08] devinus_ has joined the channel
[00:08] creationix has joined the channel
[00:11] creationix has joined the channel
[00:12] creationix has joined the channel
[00:24] creationix has joined the channel
[00:25] masuidrive has joined the channel
[00:25] jed has joined the channel
[00:25] masuidrive has joined the channel
[00:26] creationix_ has joined the channel
[00:27] <masuidrive> Hi there. Do anyone have idea for profiling nodejs apps?
[00:33] sudoer has joined the channel
[00:36] bronson has joined the channel
[00:47] Asparagusto has left the channel
[00:52] robrighter has joined the channel
[00:59] <creationix> masuidrive: node-bench is great for small snippets
[01:03] unomi has joined the channel
[01:09] jed has joined the channel
[01:10] Asparagusto has joined the channel
[01:10] Asparagusto has left the channel
[01:12] towski has joined the channel
[01:16] <masuidrive> creationix Thank you, I'll check node-bench.
[01:21] mjr__ has joined the channel
[01:23] softdrink has joined the channel
[01:38] bronson has joined the channel
[01:38] <devinus> _ry: i wish exec worked more like spawn
[01:38] <devinus> _ry: with args as an array
[01:47] dgathright has joined the channel
[01:53] Asparagusto has joined the channel
[01:53] Asparagusto has left the channel
[01:56] quirkey has joined the channel
[01:57] devinus_ has joined the channel
[02:04] BryanWB has joined the channel
[02:06] dnolen has joined the channel
[02:09] <fictorial> _ry: Node.js HEAD or Redis HEAD? I'm working on a refactor for Node.js 0.1.33 and Redis 1.3.8. I was going to try for Node.js HEAD but that bug that we were talking about yesterday stopped me.
[02:10] <fictorial> er, refactor of my redis client, not node of course.
[02:10] ditesh|cassini has joined the channel
[02:17] freshtonic has joined the channel
[02:17] dgathright has joined the channel
[02:21] dgathright has joined the channel
[02:31] softdrink has joined the channel
[02:32] RayMorgan has joined the channel
[02:39] gf3_ has joined the channel
[02:44] malkomalko has joined the channel
[02:51] statim1 has joined the channel
[02:51] tlrobinson_ has joined the channel
[02:52] devinus_ has joined the channel
[02:55] micheil has joined the channel
[02:55] devinus__ has joined the channel
[02:57] devinus__ has joined the channel
[03:00] RayMorgan has joined the channel
[03:02] brainproxy has joined the channel
[03:03] kenneth_reitz has joined the channel
[03:18] softdrink has joined the channel
[03:34] freshtonic has joined the channel
[03:35] tlrobinson_ has joined the channel
[03:37] sztanphet has joined the channel
[03:47] tlrobinson_ has joined the channel
[03:50] PyroPete1 has joined the channel
[03:58] fizx has joined the channel
[04:00] RayMorgan has joined the channel
[04:00] bronson has joined the channel
[04:02] steadicat has joined the channel
[04:04] dgathright has joined the channel
[04:04] mikeal has joined the channel
[04:05] derferman has joined the channel
[04:06] charlesjolley has joined the channel
[04:07] masuidrive has joined the channel
[04:07] dnolen has joined the channel
[04:10] hassox has joined the channel
[04:10] towski has joined the channel
[04:14] ditesh|cassini has joined the channel
[04:32] masuidrive has left the channel
[04:36] bronson has joined the channel
[04:42] creationix has joined the channel
[04:42] <creationix> aww, no tj
[04:43] <creationix> I released a new version of haml-js.  After two days of optimizing and re-writing I realized it's silly to reduce a 200ms operation at server startup to 20ms as the cost of ugly and impossible to maintain code.
[04:45] <creationix> now to get some sleep and attack the next item on my list.
[04:49] zol has joined the channel
[04:49] <zol> hello
[04:51] <zol> has anyone been able to install node.js with gnutls on CentOS 5.x?
[04:51] <zol> (64 bit
[04:53] <zol> (I am not able to pass the configure step - CentOS seems to ship with gnutls 1.4.x and I was not able to upgrade)
[04:53] <maritz> hey, node keeps crashing for me since the last 5 commits, each with different error messages...
[04:53] <maritz> APRIL FOOLS!
[04:53] <maritz> oh god... i'm bored
[04:59] <fizx> hey, where'd that byte buffer datatype go?!@
[04:59] tlrobinson_ has joined the channel
[05:01] dgathright_ has joined the channel
[05:15] shirro has joined the channel
[05:16] mikeal has joined the channel
[05:27] nsm has joined the channel
[05:42] nsm has joined the channel
[05:47] kreitz has joined the channel
[05:48] <rektide> RayMorgan: is there any way to step through a mu compilation?
[05:49] rtl has joined the channel
[05:49] <RayMorgan> rektide: what do you mean?
[05:49] <rektide> so the data event spits out fragments
[05:49] cainus_ has joined the channel
[05:49] hassox has joined the channel
[05:50] zuk has joined the channel
[05:50] <rektide> i'm interested in getting a fragment, having mu stop, and then perhaps sending an event to mu to tell it to continue running the template
[05:50] <rektide> i dont know what boundaies mu uses for streaming output
[05:50] kreitz has joined the channel
[05:50] <RayMorgan> ah, so like being able to pause the rendering process
[05:50] <rektide> yeah
[05:51] <rektide> exactly
[05:51] <RayMorgan> I am looking into adding something like this, I had a working version awhile back, but it hurt performance so I scrapped that approach. I have had a few people ask for this, so I am looking into a good way to do this again 
[05:51] mattly has joined the channel
[05:52] <RayMorgan> Currently, you can't really pause it.
[05:53] <rektide> its interesting trying to consider what makes natural pause boundaries
[05:53] <RayMorgan> yeah
[05:54] <RayMorgan> you can call .pause() on the stream now, but it will just buffer the result until you resume it for now. It emits data events in chunks of 1024 bytes by default (totally random)
[05:55] <rektide> i kind of lament mustache's simplicity here
[05:55] <rektide> it'd be nice to have arbitrary code evaluation
[05:55] <rektide> <% %>
[05:55] <rektide> i dont know if that really helps what i'm thinking of or not
[05:55] <rektide> but some way to, in the template, assert breakpoints
[05:56] <rektide> i have specific points i want to defer on, until the template's context object is ready
[05:57] <RayMorgan> ah, I am also working to allow the context to have async attributes, much like asyncEJS does
[05:57] <rektide> "hi my name is {{name}}{{*}} and i say {{reply}}"
[05:57] <rektide> i havent seen asyncejs yet, looking now
[05:58] <RayMorgan> so in the example above if {{name}} needed to be looked up from a DB, you could do that in the context and then the rendering would halt on that and then resume when told (and a result is given)
[05:58] <rektide> name would be ready
[05:58] <rektide> then {{*}} would be a "break"
[05:59] <RayMorgan> why break there?
[05:59] <rektide> the reply part is what needs to be looked up, and mu would be ssignalled when ready
[06:00] <rektide> its maybe not the most logical or meaningful example, i just staged it assuming {{name}} was known but {{reply}} would be coming later
[06:00] <RayMorgan> yeah, same idea, except the template shouldn't say halt, the context should let Mu know that a certain property needs some async work and it should resume once that is done
[06:00] <rektide> i'm trying to grok async templates now
[06:01] <RayMorgan> yeah, it makes things interesting
[06:01] <rektide> well, async templates in this case
[06:01] <rektide> are just arbitrary code
[06:01] <rektide> outside templating
[06:01] <rektide> in asyncejs
[06:01] felixge has joined the channel
[06:01] felixge has joined the channel
[06:01] <RayMorgan> yeah
[06:01] <rektide> "here, run some process and tell me when ready"
[06:01] <RayMorgan> you would do the same, but in the context
[06:01] <rektide> but it has that key break resume
[06:03] <RayMorgan> {name: "jim", reply: function (resume) { db.get(1, function (res) { resume(res.reply); }); return Mu.async; }}
[06:03] <RayMorgan> something like that
[06:03] <RayMorgan> still looking into different APIs
[06:03] <RayMorgan> but that would allow you to do something async, and the rendering would halt until resume() is called
[06:04] <rektide> keeping the fact that its async as an element of the context
[06:04] <rektide> rather than the template
[06:04] <rektide> that has potential
[06:05] <RayMorgan> exactly, that way the template doesn't have to know
[06:09] <RayMorgan> Alright, I have to take off. gn
[06:09] <rektide> i am wayy to entertained building my own testing framework
[06:09] <rektide> :/
[06:10] <rektide> yes streaming templating engines, thats _exactly_ what i need to drive my testing frameworks expected output
[06:13] sh1m has joined the channel
[06:20] micheil_mbp has joined the channel
[06:37] dgathright has joined the channel
[06:38] qFox has joined the channel
[06:47] bpot has joined the channel
[06:56] javajunky has joined the channel
[07:01] freshtonic has joined the channel
[07:17] hassox has joined the channel
[07:24] Gruni has joined the channel
[07:28] jed has joined the channel
[07:29] kixxauth has joined the channel
[07:47] javajunky has joined the channel
[07:57] amerine has joined the channel
[08:05] teemow has joined the channel
[08:11] tbassetto has joined the channel
[08:16] towski has joined the channel
[08:20] TomY has joined the channel
[08:23] hassox has joined the channel
[08:29] xla has joined the channel
[08:32] piranha has joined the channel
[08:33] mailmn has joined the channel
[08:41] felixge has joined the channel
[08:41] felixge has joined the channel
[08:45] hassox has joined the channel
[08:47] markwubben has joined the channel
[08:49] xla has joined the channel
[08:49] csarven has joined the channel
[08:52] sztanpet has joined the channel
[08:53] <csarven> Does Node.js primarily output HTML? Can't it do callbacks on the JS in the document output?
[08:57] <javajunky> csarven: err node.js doesn't neccessarily do anything with Html ?
[08:58] xla has joined the channel
[08:58] <csarven> oh, my bad, I thought it was HTML as opposed to system output
[09:01] keeto has joined the channel
[09:15] pdelgallego has joined the channel
[09:28] maushu has joined the channel
[09:33] tlrobinson_ has joined the channel
[09:35] tisba has joined the channel
[09:48] admc has joined the channel
[10:07] dekroning has joined the channel
[10:13] hellp has joined the channel
[10:28] demolithion has joined the channel
[10:37] derbumi has joined the channel
[10:43] derbumi has joined the channel
[10:53] trochala has joined the channel
[10:54] caolanm has joined the channel
[10:54] <caolanm> I seem to remember talk of a no-cache require(), did that ever materialise?
[10:56] <caolanm> I'd like to make sure I have a 'clean' object representing that module...
[11:02] ssteinerX has joined the channel
[11:11] confounds has joined the channel
[11:14] kriszyp has joined the channel
[11:30] cainus_ has joined the channel
[11:32] ithinkihaveacat has joined the channel
[11:39] ithinkihaveacat has joined the channel
[11:42] Tim_Smart has joined the channel
[11:52] mailmn has joined the channel
[11:54] voodootikigod__ has joined the channel
[11:54] <voodootikigod__> It is with a heavy heart that we make this announcement, JSConf has been cancelled, details available: http://jsconf.us/2010
[12:00] kenneth_reitz has joined the channel
[12:12] tav has joined the channel
[12:13] <javajunky> chortle
[12:18] tav has joined the channel
[12:20] broofa has joined the channel
[12:35] ditesh|cassini has joined the channel
[12:37] kriszyp has joined the channel
[12:38] dnolen has joined the channel
[12:58] gf3 has joined the channel
[13:05] jed has joined the channel
[13:07] paul___ has joined the channel
[13:08] voodootikigod__ has joined the channel
[13:10] jherdman has joined the channel
[13:13] MattCampbell has joined the channel
[13:15] davidsklar has joined the channel
[13:15] weepy has joined the channel
[13:16] <weepy> hi - does anyone know about the 0.1.33 release ?
[13:16] <weepy> I installed and obviously all the API's have changed
[13:16] <weepy> I was wondering if the biggest breakages had occured
[13:16] <weepy> or whether there was much more to come ?
[13:17] <javajunky> um, yeah it gets worse after 0.1.33 ;) 
[13:18] <javajunky> have you *really* installed the 0.1.33 release or just pointed at MASTER HEAD/TIP
[13:18] <javajunky> ?
[13:23] confounds has joined the channel
[13:23] <weepy> i dloaded it from nodejs
[13:24] <weepy> so question - what's the better upgrade path, should i fix up with 0.1.33, then fixup upon the next release
[13:24] <weepy> or just wait ?
[13:25] <weepy> i know there's this big net2 changeover
[13:25] <weepy> presumably that's the milestone her ?
[13:26] BryanWB has joined the channel
[13:29] <javajunky> the big net2 changeover has happened inside of master already, but yes I'd *imagine* (have no evidence) that those changes would be in the next official release.
[13:30] <javajunky> There's a page on the wiki describing the relative compatabilities of node versions vs libraries/modules which is where the problems occur. â€¦ personally I work against master, but you have ot be pretty brave, and I wouldn't recommend asking support/help like questions when you're not against an official release ;)
[13:33] dekroning has joined the channel
[13:34] dekroning has joined the channel
[13:39] <weepy> thanks javajunky - checking wiki now
[13:41] rtl has joined the channel
[13:48] robrighter has joined the channel
[13:52] rtl has joined the channel
[13:53] micheil has joined the channel
[13:57] xla has joined the channel
[13:58] paul_____ has joined the channel
[14:10] dnolen has joined the channel
[14:13] jed has joined the channel
[14:15] cpleppert has joined the channel
[14:19] jage has joined the channel
[14:21] gf3_ has joined the channel
[14:23] Yuffster has joined the channel
[14:24] aryounce has joined the channel
[14:26] binary42 has joined the channel
[14:27] quirkey has joined the channel
[14:35] rtl has joined the channel
[14:39] alex-desktop has joined the channel
[14:46] sudoer has joined the channel
[14:51] softdrink has joined the channel
[14:58] broofa has joined the channel
[14:58] broofa1 has joined the channel
[15:02] CodeOfficer has joined the channel
[15:08] keeto has joined the channel
[15:12] piranha has joined the channel
[15:12] Gruni has joined the channel
[15:13] tlrobinson_ has joined the channel
[15:15] creationix has joined the channel
[15:22] steadicat has joined the channel
[15:23] pdelgallego has joined the channel
[15:28] <deanlandolt> jan____: what's the formatting required for track b registrations? i'm using a valid json list of strings :_/
[15:29] <jan____> deanlandolt: I just entered plain tet
[15:29] <jan____> text
[15:30] <deanlandolt> it's yelling at me w/ plain text...hmm
[15:30] <jan____> voodootikigod_: ping
[15:30] <voodootikigod_> haha
[15:30] <voodootikigod_> hold on
[15:30] xla has joined the channel
[15:31] <deanlandolt> i figured it would be cheating to ask voodootikigod_ :D
[15:31] <voodootikigod_> what is the output you are getting
[15:31] <voodootikigod_> ?
[15:32] <deanlandolt> voodootikigod_: got it...
[15:32] <deanlandolt> it was choking in chrome
[15:32] <voodootikigod_> hmm
[15:32] sh1mmer has joined the channel
[15:32] <voodootikigod_> strange
[15:32] <deanlandolt> bitching about data:[] so i thought you'd threw in a json requirement easter egg
[15:33] <voodootikigod_> hahahahha
[15:33] <voodootikigod_> no
[15:33] <voodootikigod_> i figured the somalian pirate would be enough
[15:33] botanicus has joined the channel
[15:33] <voodootikigod_> that evidently i am a rascist for not adding awhite pirate
[15:33] binary42 has joined the channel
[15:34] <deanlandolt> how many white somalis are there?
[15:35] xla has joined the channel
[15:36] <voodootikigod_> 0
[15:37] <deanlandolt> voodootikigod_: the formatting got completely crushed though...oh well
[15:37] <deanlandolt> slashes and commas be dmaned
[15:38] around has joined the channel
[15:40] <botanicus> Hey guys. I'm wondering about the hot code reloading. I read http://romeda.org/blog/2010/01/hot-code-loading-in-nodejs.html but I can't found anywhere if it will be supported officially?
[15:45] kixxauth has joined the channel
[15:51] binary42 has joined the channel
[15:51] sh1mmer has joined the channel
[15:55] RayMorgan has joined the channel
[15:59] amerine has joined the channel
[16:00] BRMatt has joined the channel
[16:01] robrighter has joined the channel
[16:03] technoweenie has joined the channel
[16:05] <creationix> does anyone here know git?
[16:06] <creationix> specifically how to pull the version of a file with a given tag
[16:06] <creationix> I want to treat a git repo like a document database
[16:06] <creationix> if not I can try the #git room
[16:06] <creationix> I'm workin on a real engine for howtonode with versioning
[16:11] kenneth_reitz has joined the channel
[16:12] kenneth_reitz has joined the channel
[16:13] derferman has joined the channel
[16:13] <creationix> found it, git show sha1:path
[16:14] sh1mmer has joined the channel
[16:14] <mjr__> git is fantastic and terrifying to me.
[16:20] towski has joined the channel
[16:21] juvenn has joined the channel
[16:24] bpot has joined the channel
[16:31] r11t has joined the channel
[16:33] <technoweenie> creationix: are you writing the git engine in node too
[16:33] binary42 has joined the channel
[16:33] <creationix> yep
[16:33] <technoweenie> how? shell commands?
[16:33] <creationix> I'm only exposing the parts of git I need for the blog, but it should be easy to extend when I'm done
[16:33] <creationix> childprocess, yes
[16:34] <technoweenie> cool
[16:34] <creationix> got this so far http://pastie.org/899065
[16:35] <technoweenie> what is sys.p?
[16:35] <creationix> sys.puts(sys.inspect()) 
[16:35] <creationix> not sure it's documented though
[16:35] towski has joined the channel
[16:36] <technoweenie> oh wow heh
[16:36] <creationix> though I wish is did syncronous output like sys.error and sys.debug do
[16:37] <javajunky> I did not know that (sys.p) sweet.
[16:37] <javajunky> I assumed it was it was a straight alias for sys.puts <g>
[16:39] silentrob has joined the channel
[16:41] <juvenn> hello, where's process.tcp going in 0.1.33 release?
[16:42] <javajunky> I thought 0.1.33 *was* released?
[16:43] voxpelli-laptop has joined the channel
[16:44] <juvenn> javajunky: yes, I mean the tcp is not available in this released 33.
[16:44] <javajunky> iirc it was 'net' in 33 ? 
[16:44] <javajunky> is that what you mean ?
[16:47] <juvenn> javajunky: sorry. I require('tcp'), and I'd expect process.tcp.Connection() will return me a connection. But it's not, and complained that process.tcp undefined.
[16:47] softdrink has joined the channel
[16:47] <juvenn> javajunky: what might be wrong? thx
[16:48] <javajunky> yeah I don't think thats what you would do  'require' doesn't add stuff to 'process' .. so err..in your case (although I think its invalid) you'd do var tcp= require('tcp'); tcp.Connection();  â€¦ I believe
[16:50] <juvenn> javajunky: I think so, too. But I'm playing with redis-node-client, where it uses process.tcp.Connection(). And with v33, node complains that process.tcp `undefined`. Weird then.
[16:51] <fictorial> Yeah I'm updating redis-node-client now to work with node 0.1.33
[16:51] fizx has joined the channel
[16:52] <juvenn> oh, thx fictorial
[16:52] <juvenn> would you correct me?
[16:52] <fictorial> You can watch me update the node_0_1_33_redis_multi_bulk branch
[16:52] <juvenn> ok, thx
[16:54] jbowman has joined the channel
[16:55] technoweenie has joined the channel
[16:55] <juvenn> fictorial: yep, now it just use the required tcp.
[16:56] <fictorial> Yes. Later I'll switch to net.Stream and perhaps Buffer (not sure on the latter)
[16:56] <softdrink> how on earth is node development going so freaking fast?
[16:56] <juvenn> great, i'll checkout then
[16:56] <softdrink> much awesome.
[16:56] <_ry> fictorial: i got it working with node HEAD - seems to work
[16:57] <fictorial> cool
[16:57] <fictorial> the issue I had the other day is fixed then?
[16:57] <fictorial> _readwatcher not being set or something?
[16:57] <_ry> i just had to :%s/tcp/net/ and :%s/new tcp.Connection/new net.Stream/g
[16:57] <_ry> i don't know about that issue
[16:57] <fictorial> oh I sent you a gist
[16:58] <fictorial> http://gist.github.com/349765
[16:58] <_ry> oh right
[16:58] <_ry> yeah that was fixed
[16:58] dgathright has joined the channel
[16:58] <fictorial> ok that makes bringing redis-node-client up to HEAD easy then - thanks.
[16:59] <_ry> in da16128bf6e4c4d4b9ce4f57475a531c529c4910
[16:59] derbumi has joined the channel
[16:59] sh1mmer has joined the channel
[16:59] <fictorial> Is there any strong reason to use Buffer over say just a simple string for this?  In the new client (a big cleanup) it uses a fair amount of substring and +=
[17:00] <fictorial> e.g. starting from here http://github.com/fictorial/redis-node-client/blob/node_0_1_33_redis_multi_bulk/redisclient.js#L166
[17:01] <juvenn> _ry: where does the process object come from? which file should I look into? thx
[17:01] robrighter_ has joined the channel
[17:03] stephenlb has joined the channel
[17:03] broofa has joined the channel
[17:05] fizx_ has joined the channel
[17:07] towski has joined the channel
[17:08] <juvenn> _ry: "fatal: reference is not a tree: da16128bf6e4c4d4b9ce4f57475a531c529c4910", git checkout. sorry?
[17:09] sh1mmer has joined the channel
[17:09] Asparagusto has joined the channel
[17:09] Asparagusto has left the channel
[17:11] nsm has joined the channel
[17:19] bronson has joined the channel
[17:20] <mjr_> juvenn: if you read through node.cc and node.js, you can see process getting built.
[17:20] <_ry> juvenn: src/node.js
[17:21] <CIA-77> node: 03Tim Caswell 07master * r7af9cb9 10/ lib/sys.js : (log message trimmed)
[17:21] <CIA-77> node: Don't put an extra comma after bases in inspect.
[17:21] <CIA-77> node: { [Function] { [Function]
[17:21] <CIA-77> node: , more: true => more: true
[17:21] <CIA-77> node: , more2: true , more2: true
[17:21] <CIA-77> node: , more3: true , more3: true
[17:21] <CIA-77> node: , more3: true , more4: true
[17:31] tilgovi has joined the channel
[17:36] RayMorgan_ has joined the channel
[17:38] RayMorgan_ has joined the channel
[17:38] <creationix> I got three OwlCity albums for my birthday, this music is making me so productive!
[17:38] <creationix> I just might have the new engine to howtonode done this week after all
[18:02] dgathright has joined the channel
[18:07] robrighter has joined the channel
[18:09] dnolen has joined the channel
[18:11] maritz has joined the channel
[18:11] towski has joined the channel
[18:12] <creationix> Aarg, binary is hard
[18:12] <creationix> I'm trying to read a binary file from a git repo using a child process and then sending it to a client over http
[18:12] <mjr_> what's the problem?
[18:12] <creationix> I'm getting lots of 'GIF89a\u0010\u0000\u0010\u0000\ufffd\u001e\u0000X\ufffd'
[18:13] <creationix> I guess I need to set the encoding of the child process to be something that the http code understands
[18:13] <mjr_> did you setEncoding on the child process, per my email to the list earlier today?
[18:13] <creationix> not yet, I was hoping it wasn't needed
[18:13] <mjr_> oh, it is
[18:13] <creationix> is it on the child process itself or the stdout stream?
[18:13] <mjr_> using HEAD, you have access to the individual streams
[18:13] <creationix> yes, HEAD
[18:13] <mjr_> there's no encoding on the child itself anymore
[18:14] <mjr_> so yeah, child.stdout.setEncoding('binary');
[18:15] <mjr_> check that example I emailed earlier today that does gzip, which is pretty much the same situation.
[18:16] alex-desktop_ has joined the channel
[18:17] alex-desktop_ has joined the channel
[18:17] <creationix> hmm, doesn't seem to make a difference
[18:18] <mjr_> are you converting the buffer into a string somehow before sending to the client?
[18:19] <creationix> it's already a string just like in the gist
[18:19] <creationix> stdout = ""; stdout += chunk
[18:19] <mjr_> yeah, that part makes me nervous.
[18:19] <mjr_> The chunk is a buffer, which knows how to convert itself to a string, for stuff like that.
[18:20] <creationix> hmm, found it, I has somehow remove the binary encoding from my http write call
[18:20] <creationix> it's working now
[18:20] <creationix> so does binary work with no problem for ascii text?
[18:21] <creationix> is seems I can leave it as binary unless I want to support utf8
[18:21] <mjr_> I think it'd be better to just stream th eoutput to the http client, rather than convert buffers to strings.
[18:21] <creationix> well, I'm caching the output, so I have to store it somewhere
[18:21] <mjr_> yeah
[18:21] <creationix> it's not large content, just source files in a git repo
[18:22] <mjr_> I've served up a lot of ascii using the binary encoding.  I'm not sure why that is bad, or what the risks are.
[18:23] chakrit has joined the channel
[18:23] <creationix> sweet, I'm serving static content from a git repo (bare repo, no real files)
[18:23] <mjr_> that's cool
[18:23] <creationix> now for thy dynamic parts
[18:23] <creationix> http://github.com/creationix/wheat if you want to watch the fun
[18:24] <mjr_> I'll watch the fun once it means integrating your doc viewer. :)
[18:25] alex-desktop has joined the channel
[18:26] <creationix> I'm thinking of using this engine for the doc viewer
[18:26] admc has joined the channel
[18:26] <creationix> that way it can pull versions straight from the ry/node repo
[18:27] dnolen has joined the channel
[18:27] <mjr_> and then view any named version, right?
[18:27] pedrobelo has joined the channel
[18:28] <mjr_> Because otherwise how are we going to keep the docs straight with such a dynamic codebase.
[18:28] dnolen_ has joined the channel
[18:29] <creationix> yep, for howtonode.org I'm going to go back and tag is to match node
[18:29] <creationix> then you can see the article versions that match the node versions
[18:29] dnolen has joined the channel
[18:29] malte has joined the channel
[18:29] <mjr_> oh right.  That's the same problem I guess.
[18:30] <creationix> yeah, I'l probably so the same thing for api.markdown versions
[18:30] <creationix>  /so/do/
[18:30] alex-desktop_ has joined the channel
[18:31] <creationix> I wonder, does git keep a permanent history of all past versions
[18:31] malte has joined the channel
[18:31] <jherdman> i believe it does
[18:31] <creationix> if so, I can safely delete articles once they get outdated and it will all just work
[18:31] <creationix> and then add then back in when the author updates them
[18:31] <mjr_> nice
[18:32] <mjr_> Do you have any thoughts about how to link to the example programs?
[18:32] <creationix> yes, that's another feature I'm adding in
[18:32] <mjr_> I want to have a way to actually run those example programs as tests, so they won't go stale.
[18:32] <creationix> I'm going to extend markdown to allow external files to be code blocks
[18:33] mikeal has joined the channel
[18:33] pedrobelo has joined the channel
[18:34] <creationix> yeah, especially for node docs, there should be an automated way to run the examples
[18:35] <mjr_> I was thinking that making a dir in test and then a build target would be useful.
[18:39] aho has joined the channel
[18:40] r11t has joined the channel
[18:44] devinus has joined the channel
[18:52] brainproxy has joined the channel
[18:54] larssmit has joined the channel
[18:59] piranha has joined the channel
[19:00] teemow has joined the channel
[19:05] ayo has joined the channel
[19:06] lifo has joined the channel
[19:10] jbrantly has joined the channel
[19:11] gwoo has joined the channel
[19:17] kriszyp has joined the channel
[19:27] javajunky has joined the channel
[19:29] hellp has joined the channel
[19:30] robrighter_ has joined the channel
[19:38] dgathright has joined the channel
[19:42] javajunky has joined the channel
[19:42] dnolen has joined the channel
[19:44] botanicus has joined the channel
[19:47] rtl has joined the channel
[19:49] ivan has joined the channel
[19:51] botanicus has joined the channel
[19:53] broofa has joined the channel
[19:53] derbumi has joined the channel
[19:55] kriszyp has joined the channel
[19:56] sudoer has joined the channel
[20:06] ryan[LOL] has joined the channel
[20:17] dnolen has joined the channel
[20:42] nefD has joined the channel
[20:50] felixge has joined the channel
[20:50] felixge has joined the channel
[20:52] <felixge> _ry: that liveedit thing you linked, is that a mean april fools?
[20:52] pedrobelo has joined the channel
[20:53] <felixge> it looks really nice & real
[20:53] <felixge> :)
[20:55] kriskowal has joined the channel
[20:55] javajunky has joined the channel
[20:55] mattly has joined the channel
[20:58] <mikeal> felixge: the last edit on it from february so i doubt it's a joke :)
[20:58] <felixge> mikeal: :)
[20:58] <felixge> that's oh so very awesome
[20:58] <felixge> :)
[20:59] <mikeal> totally
[20:59] <felixge> now somebody just needs to figure out how to use it
[20:59] <mikeal> although, once the IPC stuff lands most of my code reloading needs will be handled
[20:59] <felixge> and implement a good binding for it
[20:59] <mikeal> that's in the bleeding edge branch
[20:59] <felixge> mikeal: you mean its not merged yet?
[20:59] <mikeal> nope
[20:59] <mikeal> it's just in that branch as far as I can tell
[21:00] robrighter has joined the channel
[21:00] <felixge> I see it in 2.1: http://code.google.com/p/v8/source/browse/branches/#branches/2.1/src
[21:00] <felixge> but not 2.0
[21:01] <felixge> I guess 2.2 is the latest
[21:01] <felixge> so this should be merged
[21:01] <mikeal> oh wow
[21:01] <mikeal> that has newer commits too
[21:02] <_ry> they're working on it right now
[21:02] <_ry> i doubt it's usable yet
[21:04] <_ry> eg http://groups.google.com/group/v8-dev/browse_thread/thread/25127e3192812148
[21:04] <felixge> well, but it sounds a lot better than require.uncached
[21:04] <felixge> I wonder why they even care
[21:04] <_ry> they sensed your frustration
[21:04] <_ry> no - i think it's probably for a live html editting app
[21:04] <felixge> hah, if they cared about that they'd give me context-sensitive eval
[21:04] <felixge> ;)
[21:05] Asparagusto has joined the channel
[21:05] <felixge> _ry: whatever, I'm really happy they are working on it
[21:05] <_ry> i can imagine reloading gmail every 5 seconds is annoying
[21:05] <felixge> hehe
[21:05] <_ry> (if you're developing it)
[21:05] <felixge> yeah, that makes sense
[21:06] <felixge> anyway, this is very cool
[21:06] <felixge> :)
[21:06] <_ry> yeah - it's good to get this feature from v8
[21:06] <mikeal> this is probably for some more debugger tools they want to add
[21:06] <felixge> so we should wait for it to be usable and then give it a shot
[21:06] <_ry> yeah
[21:07] <_ry> reloading modules is the suck
[21:08] masuidrive has joined the channel
[21:08] <felixge> _ry: do you think that we'll be able to even reload an entry point module that defines an http server with this?
[21:08] <mikeal> this graph is kinda scary
[21:08] <mikeal> http://couchdb.couchdb.org/graphs/_design/app/_show/compareWriteTest/f4eb5ba38837ce71c2ced8e583004b9f
[21:08] <felixge> without taking the server down
[21:08] <mikeal> that's write performance on a bad box directly to couchdb, and to a node rproxy that is sending to the same couchdb
[21:08] <felixge> mikeal: I get a DNS fail
[21:08] <_ry> felixge:no idea
[21:09] <mikeal> really?
[21:09] <_ry> me too
[21:09] <felixge> _ry: otherwise I think this will not be much different from module reloading
[21:09] <mikeal> what the hell
[21:09] <mikeal> jan____: ^^
[21:09] <_ry> not dns
[21:09] towski has joined the channel
[21:09] <mikeal> basically it shows the writes are faster proxied through node than directly to couchdb
[21:09] <mikeal> which makes no sense
[21:09] <_ry> 404
[21:10] <mjr_> ha
[21:10] <felixge> mikeal: it makes great sense, _ry commited some time traveling code for tcp packages earlier today ;)
[21:10] <mikeal> hahahaha
[21:10] <mikeal> i think there is a write bug in couchdb where it locks up a little when you slam it really ahrd
[21:10] <_ry> mikeal: yeah that's unlikely
[21:10] <_ry> could be
[21:10] <mikeal> and node introduces a 10ms delay that takes a little bit of that load off
[21:11] <felixge> mikeal: what do you use for the original requests?
[21:11] <mjr_> mikeal: I proxy a lot of couchdb writes through node, and I see very odd bursting behavior as well, but I've not been able to track it down.
[21:11] <mikeal> what i would expect the delay to be in terms of percentage is actually about the difference in the average speeds
[21:11] <mikeal> mjr_: do you run with delayed_commits = false ;
[21:11] <mjr_> whatever the default it
[21:12] <mikeal> that's not default
[21:12] <mjr_> then no
[21:12] <mikeal> you should turn that on, it'll make that burst go way way down under concurrent load
[21:12] <mjr_> Nice.  Will do.
[21:12] <mikeal> delayed_commits are for single writer performance, which you don't care about in the real world
[21:12] derferman has joined the channel
[21:12] charlesjolley has joined the channel
[21:12] <mjr_> Yeah, I have thousands of writers, and they all come in at random times and random intervals.
[21:13] <mikeal> when you're under concurrent load the write requests are actually transactions and don't return until the write is finished, but couchdb can batch the writes under concurrent load
[21:13] <mikeal> with delayed commits off that is
[21:13] <rektide> <-- building a rproxy service
[21:13] <rektide> it'll have a dbus interface some day
[21:13] <rektide> and that matters why on the web?  well, good question!
[21:13] <mikeal> delayed commits makes all the responses return immediately and batch every second, so you can get them way too backed up under concurrent load
[21:13] <mikeal> rektide: i'm writing out http load balancer
[21:14] <mikeal> you might be interested
[21:14] <rektide> got commits?
[21:14] <mikeal> it's programmable, because our routing rules need to change in real time
[21:14] <rektide> scm
[21:14] <rektide> i used apache commons chain
[21:14] <mikeal> let me check in my latest
[21:14] <mjr_> Have you guys read about twitter's unicorn lb?  http://engineering.twitter.com/2010/03/unicorn-power.html
[21:14] <mikeal> i just rewrote the client pool
[21:14] <mjr_> I want to build a load balancer like that.
[21:15] <mikeal> http://couchdb.couchdb.org/graphs/_design/app/_show/compareWriteTest/f4eb5ba38837ce71c2ced8e583004b9f
[21:15] <rektide> http://cgit.voodoowarez.com/pipe-layer/tree/src/main/nodejs/runtime.js is the runtime using apache commons-chain.
[21:15] <mikeal> http://github.com/mikeal/balance/blob/master/test/run.js
[21:15] <mikeal> sorry for the complete lack of docs
[21:15] arlolra has joined the channel
[21:15] <rektide> i can say the exact same
[21:15] <mikeal> basically you have a "route" event you listen to 
[21:16] <rektide> its a request event
[21:16] <rektide> yeah i should refactor to making it an event processor
[21:16] <mikeal> you get the request, and you can call a route() method on it
[21:16] <rektide> yup
[21:16] <mikeal> or you can call getResponse() which gives you the client response object and now you are responsible for it and it won't proxy
[21:16] <rektide> but, one of the features of this is ultimately going to be some rather byzantine routing
[21:16] <mikeal> so you can return errors and all that stuff
[21:17] <rektide> i started with a direct port of the commons chain impl and have been slowly hacking it into asychronity
[21:17] <mikeal> you can write whatever kind of routing table logic or load logic you want in the listener
[21:18] <rektide> sorry i know i'm reflecting on my own code over your design ; i'd stage my listeners to be a chain, but otherwise i like your event paradigm much better than how i handle requests
[21:18] <mikeal> i just want this to handle client pooling, proxying, client pool limits (configured by user), and automatic pausing of the streams on each side if I can't write to the socket immediately
[21:18] <mikeal> handle all the drain stuff 
[21:18] admc has joined the channel
[21:19] <mikeal> all the logic about "how" to route, that should just be programmable
[21:22] tav has joined the channel
[21:23] tav has joined the channel
[21:23] <_ry> socket.write() sucks right now
[21:23] <_ry> for large utf8
[21:24] <mikeal> i noticed
[21:24] <mikeal> i had to roll back to 0.1.33
[21:24] <rektide> mikeal: having composable tools for routing is a +++ good strategy
[21:24] <mikeal> it was just never finishing for me
[21:24] <_ry> mikeal: how large were you strings?
[21:24] <mikeal> > 10K were failing
[21:24] <rektide> an inherently asychronous deferable chain is a great abstraction for writing composable tools onto
[21:24] <mikeal> whoops
[21:25] <mikeal> greater than 10K
[21:25] <mikeal> rektide: I like going with an evented approach because it encourages a few practices, namely you can't go off and do IO *before* you route
[21:26] <mikeal> encouraging it would result in large delays
[21:26] <mikeal> since the event blocks on processing it means you have to have your routing logic readily available and updated asynchronously
[21:26] <rektide> mikeal: i dont like making deep event chains
[21:26] <rektide> for abstracted concerns
[21:26] <rektide> i like the conventional notion of a webserver having a stack of web filters a lot
[21:27] <rektide> cookie, do you have it?  path processor loads.  path processor adds more security filters on the end and calls another path processor that calls a cgi handler
[21:27] <rektide> seirously
[21:27] <mikeal> i try to make the event abstractions feel like the ones that already exist in node
[21:27] <rektide> you want to write events to throw a message all the way around that
[21:27] <ryan[LOL]> _ry i should have the cares module done before the end of the weekend
[21:28] <rektide> that is a good practice and i'll rebuild chain to not be executed and to be a listener
[21:28] <rektide> and then i think i'll have at least 33% of what you're going for
[21:28] <rektide> its the same event
[21:28] <rektide> a http response event
[21:28] <mikeal> right now I'm trying to provide all kinds of extra stuff around the client pool
[21:28] <rektide> the way i'm invoking it isnt kosher you're right
[21:28] <mikeal> so you can have connection limits and limits on the amount of pending responses
[21:29] <mikeal> http://github.com/mikeal/balance/blob/master/lib/pool.js
[21:29] <mikeal> basically I want to be able to protect a remove server from write load if it's clearly blocking on it
[21:29] <mikeal> because that server is actually on a shared VM and is going to break everyone else's server too
[21:30] <mikeal> this code isn't functional yet
[21:31] <mikeal> does sys.inherit only work on objects with a prototype?
[21:32] alex-desktop_ has joined the channel
[21:43] rtl has joined the channel
[21:45] <mjr_> _ry: are large writes broken for non-UTF8?  I was having trouble with large binary chunks that went away when I did smaller writes.
[21:45] siong1987 has joined the channel
[21:50] dnolen has joined the channel
[21:50] dekroning has joined the channel
[21:54] <konobi> _ry: what's with the "true" option of path.normalize() ?
[21:54] cloudhead has joined the channel
[21:54] <_ry> konobi: i don't know
[21:55] <konobi> _ry: (from the tests)
[21:55] <_ry> :)
[21:56] <_ry>   exports.normalize = function (path, keepBlanks) { 
[21:56] <_ry>     return exports.normalizeArray(path.split("/"), keepBlanks).join("/");
[21:56] <_ry>   };
[21:56] <konobi> ah
[21:59] RayMorgan_ has joined the channel
[21:59] siong1987 has joined the channel
[22:09] xer0x has joined the channel
[22:09] rictic has joined the channel
[22:15] dgathright_ has joined the channel
[22:21] <devinus> does anybody have an up to date node.js textmate bundle ?
[22:28] <jan____> mikeal: wha?
[22:32] robrighter_ has joined the channel
[22:47] kriskowal_ has joined the channel
[22:48] kriskowal_ has joined the channel
[22:48] <_ry> okay
[22:48] <_ry> sped up the write very much
[22:48] <_ry> i think
[22:49] <_ry> but lost utf8 support. need this patch to land http://codereview.chromium.org/1539013
[22:55] <devinus> does an stdout 'data' listener spit everything out on data completed ?
[22:55] <CIA-77> node: 03Ryan Dahl 07master * r3197cf2 10/ (lib/net.js src/node_net2.cc): 
[22:55] <CIA-77> node: Better flushing
[22:55] <CIA-77> node: Lost Utf8 support. Waiting for http://codereview.chromium.org/1539013 - http://bit.ly/cGessX
[22:56] <_ry> devinus: what do you mean?
[22:56] <devinus> _ry: i'm trying to use spawn() and not exec since i hate exec's API, can I i listen to a child_process and just wait till it's dont to get its output ?
[22:58] <_ry> devinus: you have to buffer it
[22:58] botanicus has joined the channel
[22:58] <devinus> frak
[22:59] <_ry> devinus: checkout the impementation of exec()
[22:59] <_ry> lib/child_process.js
[23:01] <mikeal> jan____: people are saying they can't resolve the DNS for couchdb.couchdb.org
[23:01] <_ry> mikeal: try head
[23:01] <mikeal> which is weird because this guy was connecting to it today http://japhr.blogspot.com/
[23:01] <_ry> mikeal: see if your problem is still around
[23:01] <mikeal> _ry: ok
[23:02] RayMorgan has joined the channel
[23:07] <mikeal> _ry: it's actually worse now
[23:08] <mikeal> anything over 1K i get a client error emitted after the response is recieved
[23:08] <mikeal> sorry, under 1K
[23:08] <mikeal> anything over never finishes flushing
[23:08] <mikeal> this is with the http client, btw
[23:08] <_ry> hm
[23:08] <_ry> so - worse? :)
[23:08] <mikeal> yup
[23:08] <_ry> is that 8-bit clean text?
[23:09] <mikeal> it's straight out of JSON.stringify and sent as utf8
[23:10] <_ry> ok
[23:10] <_ry> :/
[23:12] creationix has joined the channel
[23:13] <_ry> mikeal: you should use ascii if you send json
[23:13] <_ry> it's much faster
[23:13] <_ry> but that's not the issue atm
[23:13] <mikeal> it's not faster for couchdb to parse
[23:14] <mikeal> i was using ascii at one point and having issues
[23:14] <_ry> it should be the same data - just how node writes it to socket it slightly different
[23:14] <mikeal> hrm.....
[23:15] <_ry> anything that comes out of JSON.stringify() is ascii
[23:15] <mikeal> i wonder what it was then
[23:15] <mikeal> it was noticeably slower
[23:15] <_ry> i'm a bit sceptical of your claim that it doesn't work
[23:16] <_ry> skeptical even
[23:16] <ryan[LOL]> ry it's possible that you could do your thing without modifying v8
[23:16] <ryan[LOL]> to return number of chars written
[23:16] <_ry> RayMorgan: how?
[23:16] <ryan[LOL]> though at some cpu expense
[23:16] <_ry> ryan[LOL]: how?
[23:16] <mikeal> let me write a test case
[23:16] <ryan[LOL]> ry you could take the num of bytes written
[23:17] <ryan[LOL]> and then build a character count by doing an additional string parse
[23:17] <_ry> oh right
[23:17] <_ry> yeah i can read over the data again, make a new string
[23:17] <_ry> count the cars
[23:17] <ryan[LOL]> i have a utf8 encoder/decoder thing
[23:17] <ryan[LOL]> that is real small
[23:17] <ryan[LOL]> that might help with that
[23:17] <_ry> i mean, v8 does too
[23:17] <ryan[LOL]> ok
[23:17] <ryan[LOL]> yeah use that then
[23:18] <ryan[LOL]> but at least you could have a workaround until that patch gets accepted
[23:18] <ryan[LOL]> does the v8 decoder do something like take a certain # of bytes and count how many characters that is and return a remainder
[23:19] <ryan[LOL]> for instance it could be a 3 byte segment of utf-8 (like a CJK char)
[23:19] <ryan[LOL]> and it could have written 2 of them leaving an invalid codepoint
[23:19] <ryan[LOL]> so in a case like that it'd return a 0 remainder 2
[23:19] <kriskowal> _ry iconv does provide byte counts for both source and target buffers, and a character conversion count. it seems that iconv is in libc when it's not in libiconv
[23:20] <kriskowal> ashb has some sample code for determining whether it's in libc or libiconv at configure time
[23:20] dnolen has joined the channel
[23:21] <kriskowal> but using it probably pushes windows compatibility farther away; i'm not sure what you do for transcoding on windows.
[23:21] <_ry> at this point i'm only concerned with utf8
[23:22] <ryan[LOL]> utf16 and utf32 are pretty easy
[23:22] <ryan[LOL]> the only thing with utf16 is the surrogate pairs
[23:22] <_ry> utf16 can be done someday - utf32 will require hacking 
[23:22] <ryan[LOL]> the nice thing about utf-32 is there's a 1:1 mapping
[23:22] <ryan[LOL]> each code point is just one 32bit deal
[23:23] <ryan[LOL]> if you only handle UCS 2.0 and the BMP you can do utf-16 very very easily
[23:23] <kriskowal> anyone know whether v8 stores strings in ucs-16? it's my understanding that the full 24 bit code plane is not even expressible
[23:24] <ryan[LOL]> kriskowal if it handles the surrogate pair points then yeah it does the old ghetto way
[23:24] <ryan[LOL]> er if it doesn't handle the surrogate pair points
[23:24] <ryan[LOL]> a lot of people claim unicode support but they only handle BMP 
[23:26] <CIA-77> node: 03Ryan Dahl 07master * re232cf3 10/ lib/net.js : Hack to support UTF8 writes again! - http://bit.ly/cPE0Qk
[23:26] charlesjolley has joined the channel
[23:26] <inimino> _ry: JSON.stringify in V8 happens to only return ASCII, but that's a quirk of V8, it's not specified that way
[23:26] <_ry> mikeal: try with this. mabe there was some utf8 data in your stuff
[23:26] <_ry> inimino: json doesn't allow utf8 afaik
[23:26] <mikeal> _ry: i have a test
[23:27] <ryan[LOL]> json has a very strict specification
[23:27] <_ry> mikeal: okay
[23:27] <mikeal>  hold on, cleaning it up
[23:27] <ryan[LOL]> it's not like haxml
[23:27] <inimino> _ry: it's encoding-neutral, but it's not at all restricted to ASCII
[23:28] <ryan[LOL]> http://www.json.org/
[23:28] <ryan[LOL]> ^^ ther'es a big thing on the front page
[23:28] <ryan[LOL]> saying how to parse it
[23:28] <_ry> inimino: just checked the site, your gith
[23:28] <_ry> right
[23:29] <ryan[LOL]> the string can have unicode characters
[23:29] <ryan[LOL]> but the json structure itself can't
[23:30] rolfb has joined the channel
[23:31] <ryan[LOL]> the way that i see a lot of people do it
[23:31] <ryan[LOL]> is they encode unicude using \u0001 etc. etc.
[23:31] <ryan[LOL]> in a string so like
[23:32] <ryan[LOL]> { "lol" : "\u0001 lol \u0002" }
[23:32] <_ry> ACTION <3 net.js
[23:33] <ryan[LOL]> still it's infinitely better than haxml
[23:33] <ryan[LOL]> </3 xml'
[23:33] mattly has joined the channel
[23:34] <ryan[LOL]> if you insist on the escaped-encoding of unicode then you'll be able to enforce ascii-only on the json structure
[23:34] <ryan[LOL]> and if someone complains they can die in a fire
[23:35] <inimino> I would complain very loudly if any software I used that claimed JSON support did that :-)
[23:35] <inimino> anyway, bbl
[23:35] <jed> funny how the only speaker slots left at jsconf are those opposite _ry: http://jsconf.us/2010/schedule.html
[23:35] <ryan[LOL]> inimino and you don't complain loudly at the 309209420920 softwares that support unicode by only supporting a subset of utf-16 BMP? :)
[23:36] <mikeal> yeah, i can't make the test show this behavior
[23:36] <ryan[LOL]> oo
[23:36] <mikeal> so it's gotta be my data
[23:37] <_ry> oh yeah. im giving a talk next week. :|
[23:37] <ryan[LOL]> i wish i could go to washington dc and speak
[23:37] <inimino> ryan[LOL]: yes, I complain about those too, in fact I went to great lengths to support supplementary characters in a project of mine
[23:37] <inimino> ACTION is really away, bbl
[23:37] <ryan[LOL]> inimino i wrote a utf-8 encoder/decoder out of rage :<
[23:38] <_ry> mikeal: okay - i'm seeing some error
[23:38] <_ry> there must be a race somewhere
[23:38] <ryan[LOL]> if i could go to washington dc and speak it'd be about how incredibly hilariously bad the state of html/js only audio is
[23:38] <ryan[LOL]> apparently if it's not a file embedded in the dom it doesn't matter
[23:39] <ryan[LOL]> it's not like something like a game would ever need to have audio processing
[23:39] <ryan[LOL]> and it's not like a large percentage of flash usage is for games
[23:40] <mjr_> And also, why no mic support?
[23:40] <mikeal> _ry: that last commit didn't help
[23:40] <ryan[LOL]> mjr i imagine due to security issues and implementation but yeah
[23:40] <ryan[LOL]> they should have a "allow this page to access my speakerz and mic "
[23:40] <ryan[LOL]> kind of like how flash has webcam/mic security
[23:40] <mjr_> Which is what flash does, and somehow everybody let's Flash be on their computers and enabled.
[23:41] <ryan[LOL]> yes well the issue is that html5/canvas/svg/etc. don't provide a viable alternative to flash
[23:41] <mikeal> not me :)
[23:41] <mikeal> ryan[LOL]: they don't?
[23:41] <ryan[LOL]> no
[23:42] <ryan[LOL]> canvas is horrendously slow
[23:42] <mjr_> Not for a lot of stuff, they don't.
[23:42] <mikeal> other than hacking your webcam
[23:42] <ryan[LOL]> even on chrome
[23:42] <mikeal> canvas is awesome
[23:42] <mikeal> it's not slow with graphics acceleration
[23:42] <mikeal> which is what everyone is working on
[23:42] <ryan[LOL]> yeah well
[23:42] <_ry> mikeal: hmm i wonder what it is
[23:42] <mikeal> there is some code in FF trunk that has graphics acceleration for some canvas operations and all CSS transitions
[23:43] <mikeal> _ry: i don't know, but it works fine in 0.1.33
[23:43] <ryan[LOL]> mikeal there's also some code in a pending FF patch that allows realtime audio mixing and analysis from js
[23:43] <mjr_> canvas is pretty snappy on Safari + 10.6, and then add in GPU accelerated CSS for even more goodness.
[23:43] <_ry> mikeal: 0.1.33 was a long time ago
[23:43] <_ry> :)
[23:43] <ryan[LOL]> but that probably won't ever mainline
[23:43] <ryan[LOL]> mjr it's not snappy
[23:43] <mikeal> _ry: a decade in node years :)
[23:43] <ryan[LOL]> snappy compared to previous versions of canvas
[23:43] <ryan[LOL]> but not compared to flash
[23:44] <_ry> mikeal: did it work in aa6a7852868b341776ea7ebfa9f291f88c533dda
[23:44] <mikeal> i don't care how fast it is when it makes my laptop so hot my balls start sweating 
[23:44] <mjr_> Well, flash is do damned slow on OSX, that it sets a pretty low bar for performance.
[23:44] <ryan[LOL]> and certainly not compared to a really slow SDL app
[23:44] <_ry> mikeal: by which i mean d1b78c3f5d948728dcee852a9c2bfd59f4e01fbd^
[23:44] <mikeal> it hasn't worked since the net2 merged
[23:44] <_ry> oh okay
[23:44] <mikeal> whatever checkin that was
[23:44] <ryan[LOL]> i've been writing graphics crap since the MS DOS days and it's bad when i can comfortably say that graphics crap i wrote for a 386/25 and a VGA
[23:44] <ryan[LOL]> runs leaps and bounds faster than a canvas context on a dual core laptop
[23:45] <_ry> mikeal: hmm 
[23:45] <ryan[LOL]> which is an embarrassment no matter how you draw it up
[23:45] <mikeal> the canvas standard was just finalized
[23:45] <_ry> mikeal: you should really do a test case
[23:45] <mikeal> it's fairly common to implement an API and just get it working, then optimize it
[23:46] <mikeal> i did, and it didn't expose the bug :)
[23:46] <_ry> is the code online?
[23:46] <mikeal> i can't track down what it is about this data that is making it do this
[23:46] <mikeal> it could be in a few seconds, but it's a POST to couchdb
[23:46] <ryan[LOL]> hold on let me find an interactive reason why canvas is slow
[23:46] <ryan[LOL]> from something i wrote
[23:46] <mikeal> if you have a server that just response to any request, that'll work too
[23:47] <JimBastard> so now i have a macbook pro and a netbook running ubuntu, i guess i have no reason for not having a local node dev env
[23:47] <ryan[LOL]> http://www.diod.es/ryanwin/jzzzt/src/index.html
[23:47] <ryan[LOL]> ^^ i am trying to implement a text mode game
[23:47] <ryan[LOL]> a TEXT MODE game using canvas
[23:47] <ryan[LOL]> and it barely runs fast enough on my eee pc
[23:48] <CIA-77> node: 03Ryan Dahl 07master * rfdae140 10/ lib/net.js : 
[23:48] <CIA-77> node: Move buffer constants at the top of net.js
[23:48] <CIA-77> node: Remove some cruft. - http://bit.ly/9rALtD
[23:49] <JimBastard> DUDE
[23:49] <JimBastard> AWESOME UI 
[23:49] <mjr_> I guess I don't care about how slow canvas is, because the API and how it is deployed is so much more accessible than anything else.  If it weren't for canvas, I just wouldn't bother writing graphics anything.
[23:49] <mjr_> And they'll make it faster over time.
[23:49] <JimBastard> ryan[LOL]:  did you make that?
[23:50] <ryan[LOL]> JimBastard yes
[23:50] <JimBastard> +1000 points
[23:50] <JimBastard> i for one welcome our newest #node.js member
[23:51] <JimBastard> shit i just got eaten by a grue
[23:51] <ryan[LOL]> lul
[23:51] <ryan[LOL]> i actually found node.js after making a game and having to do a server back end in php
[23:51] <ryan[LOL]> just a tiny little thing as a proof of concept
[23:52] <ryan[LOL]> and i was like mannnn if only i could just do sane server side js without like a .net crap
[23:52] <mjr_> About a year ago, I wrote a canvas + XHR performance tool, that could fetch an XHR and update a somewhat complicated bar graph at 50 cycles /second.
[23:52] <mikeal> did you guys see that quake2 demo that is all canvas + webgl?
[23:52] <ryan[LOL]> http://game.ryanbroomfield.com/pilot.html
[23:52] <technoweenie> yea it flickers like crazy
[23:52] <ryan[LOL]> ^^ that one
[23:53] <mikeal> http://code.google.com/p/quake2-gwt-port
[23:53] <ryan[LOL]> the game unicode-encodes your game replay then sends to a server
[23:53] <ryan[LOL]> which validates it
[23:53] <ryan[LOL]> and adds it to the high scores list
[23:53] <ryan[LOL]> so i had to reimplement my game logic in php
[23:54] <ryan[LOL]> which is hax
[23:54] <ryan[LOL]> and unicode decode the string in php
[23:54] <ryan[LOL]> which is laughable
[23:54] <ryan[LOL]> php is horrendously bad with unicode
[23:54] <technoweenie> someone has 92k though
[23:54] <technoweenie> jesus
[23:54] <ryan[LOL]> yeah
[23:54] <ryan[LOL]> that's because he wrote an AI to play the game
[23:54] <ryan[LOL]> lul
[23:54] <technoweenie> oh
[23:54] <ryan[LOL]> i can reset the scores list
[23:57] sudoer has joined the channel
[23:57] csarven has left the channel
[23:58] <ryan[LOL]> ok
[23:58] <ryan[LOL]> scores list reset loool
[23:59] <ryan[LOL]> anyway the whole validation crap would have been awesome were it written in js instead of php so that's how i found node.js ta da
