[00:01] mikeal: cool
[00:08] kriskowal has joined the channel
[00:10] kriszyp has joined the channel
[00:12] sveisvei has joined the channel
[00:12] mjijackson has joined the channel
[00:13] hassox has joined the channel
[00:13] mattly has joined the channel
[00:14] charlesjolley_ has joined the channel
[00:14] JimBastard has joined the channel
[00:15] JimBastard: so i applied for the heroku node.js hosting 5 hours before they posted that blog post
[00:15] JimBastard: they better fucking accept me
[00:15] JimBastard: ;-)
[00:15] JimBastard: *cough* bmizerany 
[00:15] bmizerany: JimBastard: we will. :)
[00:15] JimBastard: hee hee
[00:16] JimBastard: are there any details out yet?
[00:16] bmizerany: we're super swamped with requests right now. and, you weren't supposed to know about it that early. hahah
[00:16] JimBastard: are you guys only supporting http?
[00:16] JimBastard: does everyone get their own IP address?
[00:16] bmizerany: currently, only http.
[00:16] JimBastard: aye
[00:16] JimBastard: that makes a lot of sense
[00:17] JimBastard: awesome man, i look forward to playing with it
[00:17] JimBastard: and traversing some directories mwahahahah 
[00:17] bmizerany: you can use it as a background worker too, with a little trick (unofficial).  in your workers.rb file, say `exec node worker.js` :)
[00:17] JimBastard: cool cool, im excited
[00:17] bmizerany: we're looking to the community to help drive new features for their uses
[00:18] bmizerany: hah. nice
[00:18] brapse has joined the channel
[00:18] krishna__ has joined the channel
[00:18] gleicon has joined the channel
[00:18] bmizerany: the response has been so positive.  I'm super excited about getting it out.
[00:19] bmizerany: and about using Node.  We've been using node in our architecture for some time.
[00:19] JimBastard: yeah node + ruby is a good mix for production stuff right now
[00:19] JimBastard: since ruby has such a strong backing and node solves the async issues
[00:20] mumrah_ has joined the channel
[00:20] JimBastard: im constantly making fun of our backend team at my job. im all like, what do you mean we can't keep 5k connections open at once?
[00:20] mumrah_: anyone using websockets currently?
[00:20] JimBastard: THUNDERHOOOOOOOOOO
[00:21] mumrah_: without fail
[00:21] mumrah_: i am welcomed thus
[00:21] JimBastard: :-D
[00:21] mumrah_: so, websockets?
[00:21] mumrah_: anyone?
[00:25] whoahbot has joined the channel
[00:26] zomgbie has joined the channel
[00:26] jedschmidt has joined the channel
[00:41] gf3 has joined the channel
[00:42] robrighter has joined the channel
[00:47] creationix has joined the channel
[00:52] CodeOfficer has joined the channel
[00:56] towski has joined the channel
[01:05] gwoo has joined the channel
[01:10] Dethe has joined the channel
[01:14] russell__ has joined the channel
[01:15] ditesh|cassini has joined the channel
[01:17] Dethe has joined the channel
[01:24] pgriess has joined the channel
[01:25] devinus: _ry: http://blog.heroku.com/archives/2010/4/28/node_js_support_experimental/
[01:26] Aria: Spiffy!
[01:26] sudoer has joined the channel
[01:29] _ry: i've seen ;)
[01:29] ditesh|cassini has joined the channel
[01:29] _ry: pretty cool
[01:30] softdrink has joined the channel
[01:33] _ry: DEBUG: calling chargen for 100000 chunks.
[01:33] _ry: bytesParsed: 24345, len: 24347
[01:33] _ry: 35   36   37   38   39   0d   0a   30   0d   0a   0d | 0a   
[01:33] _ry: proxy client error. sent 2000000
[01:33] _ry: Error: Parse Error
[01:33] _ry: ^--- ./node test/disabled/test-http-big-proxy-responses.js
[01:33] _ry: that | is where it breaks
[01:34] _ry: which if you decode the hex is "0\r\n\r\n"
[01:34] _ry: dies on the last \r
[01:34] _ry: er
[01:34] _ry: \n
[01:34] _ry: sounds like a parser issue...
[01:34] devinus: _ry: check out my response on the commonjs list
[01:35] devinus: i swear somebody's going to call me out soon and call me an idiot :P
[01:36] _ry: devinus: i think the point is implementations are going in two directions
[01:36] _ry: or rather - there is node and everything else
[01:36] devinus: _ry: i think implementers are scared of async or just don't know how to do it
[01:36] quirkey has joined the channel
[01:37] devinus: because that's what it's beginning to sound like
[01:37] _ry: i think they want to still support people who don't have async or don't have sync
[01:37] _ry: which is reasonable
[01:37] RayMorgan has joined the channel
[01:38] _ry: devinus: nah - they just have different ideas of what they want it to be
[01:38] _ry: most want it to be python with javascript syntax
[01:38] devinus: that's retarded
[01:38] devinus: i'm from python and i want it to stay the fuck out of my async js
[01:39] _ry: python with javascript syntax - and then build node on top - like twisted is 
[01:39] dekz has joined the channel
[01:39] devinus: _ry: dear god no
[01:39] devinus: im from twisted too
[01:39] devinus: i did that for a year
[01:39] devinus: the greatest thing about node is that it feels like async is built into the language
[01:39] devinus: like it was there from the start
[01:39] jedschmidt: i'm convinced trying to be both async and sync is a dead-end.
[01:40] jedschmidt: i'm rewriting (fab) to be 100% async, including setup.
[01:40] jedschmidt: the word "return" occurs like maybe 3 times in the whole library.
[01:40] _ry: my opinion of course is that boxing people into async forces them to write fast things - even if they don't know what they're doing
[01:41] _ry: you give them sync stuff and they're going to use it
[01:41] _ry: if you give someone a way to do a synchronous DNS look up or HTTP request - suddenly they'll start writing all these slow shitty programs :)
[01:42] _ry: if you just force them to give a callback, maybe the grumble for a few minutes - but then the program is fast
[01:43] noonat: the main time callbacks is hard is when you're going from programming sync to programming callbacks
[01:43] Aria: Yeah.
[01:43] noonat: if people would just stop complaining and do callbacks for a while it's not any harder, for the most part.
[01:43] Aria: Or when you use a language without closures.
[01:43] _ry: that said - i also wouldn't want to write batch shell script in an async way
[01:43] noonat: Aria: hahaha, yes.
[01:44] _ry: doing 10 things in a row one after another is annoying
[01:44] _ry: luckly most programs aren't that way :)
[01:44] _ry: anyway - hence the sync file i/o on node
[01:45] _ry: that's my compromise - but i'm not going any further
[01:46] micheil: the only bad part about async is the deep callback nesting
[01:46] Aria: At least once a day I curse some Apple programmer who assumed disks were infinitely fast.
[01:46] Aria: If you're nesting callbacks that much, chances are you need a state machine.
[01:47] micheil: _ry: also, had something as an issue with the http lib
[01:47] _ry: micheil: you don't need deep callback nesting
[01:47] micheil: _ry: true
[01:47] _ry: you need some abstractions
[01:47] _ry: you can abstract 10 transactions into a single callback
[01:47] _ry: you just can abstract it into a single function call
[01:47] _ry: abstraction is still possible
[01:47] micheil: _ry: with the http lib, because it automatically unbinds upon req.header.upgrade, then there's no way to rebind it
[01:48] _ry: micheil: officially the connection is dead to the http server at that point
[01:49] micheil: yeah
[01:49] micheil: although, in the case of websockets, if the connection is upgrade && GET then serve as websockets, otherwise server as http
[01:50] _ry: i'm not sure what you're saying
[01:50] towski has joined the channel
[01:51] micheil: well, is there a way to rebind the connection handlers?
[01:51] _ry: hm?
[01:52] _ry: of the server?
[01:52] micheil: say my upgrade header is only to use a special for of compression
[01:52] micheil: it's then more difficult for me to send the responses back
[01:52] tlrobinson_ has joined the channel
[01:53] micheil: as in, you don't have access to ServerResponse()
[01:53] _ry: you don't response in http after an upgrade header
[01:53] _ry: the client is requesting to change the protocol
[01:53] micheil: hm.m.
[01:53] _ry: after you get the upgrade header - the connection is no longer http
[01:54] micheil: not even one chance to respond in a http format?
[01:55] _ry: no
[01:55] micheil: hmm..
[01:56] nwhite has joined the channel
[01:56] micheil: I've misunderstood something then
[01:56] _ry: they either close the connection or speak the new protocol
[01:56] _ry: (or i've misunderstood something)
[01:59] robrighter: _ry: Is there any plan for cookie support in the http library, I recently made this change to the cookie-node library but it seems kindof wrong the way it changes the http prototype
[01:59] robrighter: http://github.com/jed/cookie-node/commit/6998d9c9e914973c6f6a67632a11d3b088b9f212
[02:00] _ry: micheil: oh you're right
[02:00] micheil: oh?
[02:00] _ry: micheil: but i'd rather the user not use node's http to respond
[02:00] _ry: just send the sever hand shake manually
[02:00] kriskowal_ has joined the channel
[02:01] _ry: robrighter: yeah-i should get that in
[02:01] _ry: no plan
[02:01] _ry: but i think its' good to have
[02:02] robrighter: gotcha, I know express has some notion of sessions too but have not looked at how they implement cookies
[02:03] micheil: that's kinda interesting, a websocket server, if it wishes can make use of http cookies as well
[02:03] _ry: i'd like the http client to have cookies too
[02:04] _ry: like automatically store them
[02:04] micheil: hmm... could that cause issues?
[02:04] _ry: maybe not on disk (initially) but for the length of a session
[02:04] micheil: isn't the response sent back with cookie headers in tact?
[02:04] _ry: would be great
[02:04] deanlandolt: does the http client do caching already?
[02:04] _ry: no
[02:05] _ry: the http client is extremely simple right now
[02:05] _ry: but i want it to be beefed up
[02:05] deanlandolt: seems like the same mechanism could roll the two together
[02:05] micheil: _ry: I must say though, implementing websockets on top of node is much easier now
[02:05] zol has joined the channel
[02:05] micheil: _ry: are there any queue implementations?
[02:05] jedschmidt: _ry: what do you have in mind for the "beefing"?
[02:05] deanlandolt: maybe even an extension to the client (requires configurable persistence at least)
[02:07] deanlandolt: seems silly to have a python-style urllib/urllib2 break but seems lke you should be able to pick the store used for your cache and cookies at runtime
[02:08] _ry: yes
[02:08] _ry: fixed issue 77 :D
[02:09] deanlandolt: 0.2 is barrelling down on us :)
[02:09] _ry: this will make couchdb peeps happy
[02:10] _ry: parser error
[02:12] voodootikigod_ has joined the channel
[02:12] Aria has joined the channel
[02:16] mjijackson has joined the channel
[02:17] isaacs: _ry: w00t!!
[02:18] micheil: _ry: the reason I ask about queues, is so that you can init a queue, set the encoding, and then just write data to the queue, then set a fixed separator for the queue
[02:19] tek has joined the channel
[02:19] micheil: eg, for websockets: new Queue(socket, "\xfffd", "utf8")
[02:21] tlrobinson__ has joined the channel
[02:29] brainproxy: hmm, a bit confused about how to serve static files through express
[02:29] brainproxy: probably missing something obvious
[02:31] _ry: micheil: you can just write to a socket
[02:31] _ry: micheil: it will queue the data
[02:31] micheil: hm..
[02:31] micheil: well, i'm thinking more an incoming queue
[02:31] _ry: oh
[02:32] micheil: and then when the delim is reached, fire an event emitter "data" with the split to it
[02:33] _ry: seems to complicated
[02:33] _ry: how about just read it in as buffers
[02:33] micheil: okay
[02:33] creationix has joined the channel
[02:33] micheil: _ry: just thinking about the implementation level stuff for node-smtp-client
[02:34] _ry: ACTION goes home. i'll upload this issue 11 fix later.
[02:34] _ry: s/11/77/
[02:34] _ry: micheil: state machine + buffer
[02:35] micheil: hmm?
[02:35] herbySk: micheil: wouldn't something like this be enough? http://gist.github.com/383044
[02:35] _ry: isaacs will explain :)
[02:35] micheil: any good resources on both?
[02:35] isaacs: what am i explaining now?
[02:35] _ry: http://github.com/isaacs/sax-js
[02:35] micheil: lol
[02:35] _ry: ACTION disappears. later
[02:36] isaacs: huh? who?
[02:36] bolson has joined the channel
[02:36] isaacs: oh, micheil, you're interested in writing a parser?
[02:36] micheil: yeah
[02:36] robrighter: creationix: something seems to be wrong at http://howtonode.org
[02:36] micheil: needing it for node-smtp-client
[02:36] isaacs: so, there are a few ways to go about it...
[02:36] creationix: robrighter: thanks
[02:37] isaacs: one is to take in a blob, append the blob to your buffer, and then use regexps to chop off the next bit to process, repeat.
[02:37] creationix: I'm getting a pipe(): Too many open files error
[02:37] isaacs: the other is to go char  by char, with a while ( c = str.charAt(++ pos)) wrapped tightly around a big scary state machine.
[02:37] micheil: yeah, like: http://github.com/miksago/node-smtp-client/blob/master/lib/vendor/Pump.js
[02:38] micheil: that's the regexp chop style
[02:38] isaacs: micheil: yeah, but not really
[02:38] creationix: robrighter: it's up again, hopefully this time I can figure out the bug that crashes it every few days
[02:38] isaacs: micheil: Pump.js is way more complicated.
[02:38] micheil: it just triggers a method, etc.
[02:38] isaacs: right
[02:38] isaacs: but i mean, why a settimeout?  etc.
[02:39] micheil: no idea
[02:39] micheil: I don't think it was queueing properly or something
[02:39] micheil: eg, emitting half packets
[02:39] isaacs: micheil: here's an example of the first way: http://github.com/isaacs/multipart-js/blob/master/lib/parse.js
[02:40] isaacs: micheil: here's an example of the second: http://github.com/isaacs/sax-js/blob/master/lib/sax.js
[02:40] isaacs: the second is, in many ways, superior.
[02:40] isaacs: it's faster, cheaper, awesomer, your states are smaller and more specific, etc.
[02:40] creationix: anybody remember how to scroll in screen?
[02:41] micheil: scrollTo
[02:41] micheil: hmm..
[02:42] isaacs: micheil: if i were writing a new parser, I'd go the sax-js route.  one char, states, and a while loop.  fer tha muthafuckin win.
[02:42] isaacs: xml's such a bitch, you really don't have much of an option.
[02:43] isaacs: and its delimiters are single-characters, so that makes it easier.
[02:43] micheil: yeah, this need is for a socket's data
[02:43] micheil: \0 or \r\n split
[02:43] isaacs: nice
[02:43] isaacs: i recommend single-byte scope.
[02:43] micheil: so, that's why I think it'd be wise to use a queue
[02:47] mikeal has joined the channel
[02:47] towski has joined the channel
[02:48] isaacs: micheil: too complicated.
[02:48] micheil: hmm, okay
[02:48] isaacs: a standalone single-char-range parser is also easier to subject to unit tests.
[02:48] mjijackson has joined the channel
[02:48] micheil: so, what happens with either parser when it reaches the end of a stream of data and doesn't find a delim?
[02:48] isaacs: micheil: it sits there.
[02:48] micheil: k
[02:49] isaacs: just like if you create a sax-js parser, and you feed it "<foo>bar<a"
[02:49] micheil: okay, that's cool
[02:49] isaacs: until you do parser.end(), it'll assume that something else is coming.
[02:49] dgathright has joined the channel
[02:49] micheil: and then as soon as I feed more data, it'll respond
[02:49] isaacs: if you do parser.end() and it's in a wonkky state, you can decide whether you want to error out, or what.
[02:49] isaacs: in sax-js's case, it depends on whether you're in strict mode or not.
[02:50] micheil: do you think it'd work to emit the data?
[02:50] cruxst has joined the channel
[02:50] isaacs: in strict mode, it emits an error.  in non-strict mode, it sorta tidies up, closes the currently open tags, etc.
[02:50] isaacs: i'm not really too familiar with the dialect you're parsing.
[02:50] tlrobinson_ has joined the channel
[02:50] micheil: eg, say I'm needing it to split on \0, so my data may be: "test\0test mesage\0another message\0
[02:50] isaacs: right.
[02:51] isaacs: so i could do something like parser.write("test\0foo").end()
[02:51] micheil: then I'd read char by char, writing the chars into a new buffer, when I reach \0, I emit the buffer out
[02:51] isaacs: ending it in an unclosed state.
[02:51] micheil: and empty
[02:51] isaacs: sure
[02:51] isaacs: you might also want to set some arbitrary maximum size, and emit it if it gets that big.
[02:51] micheil: which would give me a simple parser for that sort of data formating
[02:51] micheil: yeah
[02:51] isaacs: but don't test .length every time.
[02:52] micheil: no
[02:52] isaacs: just check it every N times
[02:52] isaacs: where N is enough time for it to be potentially too big.
[02:52] isaacs: sax-js does this
[02:52] isaacs: actually, in many ways, that little hack is the best bit of software i've ever written.
[02:53] micheil: so, it'd just be a matter of: for char by char do: if char == delim emit; else buffer.write char; end;
[02:53] isaacs: micheil: that's a pretty good sketch of it, yeah
[02:53] micheil: okay
[02:54] isaacs: micheil: also, you might have multi-char delimiters, right? \r\rn?
[02:54] isaacs: \r\n
[02:54] micheil: yeah
[02:54] isaacs: ok, then you'll need 2 states, it sounds like.
[02:55] micheil: in which case: EXPECT_NEWLINE sorta thing
[02:55] isaacs: mind you, this format might not be complex enough to even really jsutify having a state machine
[02:55] mkovacs has joined the channel
[02:55] micheil: on \r we set state to EXP..  then check against teh EXP delim
[02:55] micheil: when we hit the delim of \n then we reset back to \r 
[02:56] rednul has joined the channel
[02:56] isaacs: you could just do something like:  buffer += chunk; buffer.split(delim); for each part except the last, emit; buffer = buffer.last
[02:56] micheil: huh?
[02:57] isaacs: well, i mean, is there more to it besides "foo\0bar\0baz\0quux\0"?
[02:57] micheil: no
[02:57] micheil: i don't think so
[02:57] isaacs: ok.  then building a state machine for it would be a valuable learning exercise, but not really necessary.
[02:57] micheil: it's either a single char, like \xfffd or \0
[02:57] isaacs: right
[02:57] micheil: or it's \r\n
[02:58] deanlandolt: char-by-char still requires a state machine...just not a crazy-complicated one
[02:59] isaacs: deanlandolt: my point is that char-by-char isn't really that necessary here.
[02:59] isaacs: but, micheil, you'll be a better programmer for the experience.
[02:59] deanlandolt: so split on one of three patterns?
[02:59] isaacs: deanlandolt: well, you know what the delim is at the start.
[03:00] deanlandolt: i don't know -- any time you have a two-byte sequence and you're dealing in chunks i think char-by-char is the only way to roll
[03:00] isaacs: deanlandolt: hm, fair enough
[03:00] deanlandolt: err, two-char sequence
[03:00] deanlandolt: you can do it otherwise -- but you're asking for trouble :)
[03:01] micheil: deanlandolt: no. they are for individual apps, but generic here is the best abstraction
[03:01] isaacs: deanlandolt: i handle much more than 2-char delims in multipart-js
[03:01] deanlandolt: oh, i see -- well, i'm w/ isaacs in the general sense -- if you can get away with a split you're better for it
[03:01] isaacs: it's a little bit tricky, but not completely
[03:02] micheil: hmm.. okay
[03:02] deanlandolt: yeah, but it's not just tricky, it's full of sharp edges
[03:02] micheil: bbl.
[03:04] andrewvc has joined the channel
[03:06] deanlandolt: isaacs: also, i owe you a cross-platform, cross-engine, cross-os blogging app...the interface isn't pretty but i'll push something to github tomorrow night i think
[03:06] isaacs: deanlandolt: that'll be interesting.
[03:06] deanlandolt: won't it :)
[03:06] isaacs: deanlandolt: i really should've thrown "with a pretty interface" into the challenge.
[03:06] isaacs: crap.
[03:06] isaacs: ^_^
[03:06] deanlandolt: i'll see what i can do
[03:07] isaacs: deanlandolt: when you say "cross engine", what exactly does that mean?
[03:07] isaacs: narwhal and node?
[03:07] deanlandolt: rhino/node
[03:07] isaacs: ok
[03:07] isaacs: no love for couch and flusspferd!??
[03:07] deanlandolt: i'm not quite sure what cross-engine/cross-platform even means anymore
[03:07] deanlandolt: couch isn't a full commonjs platform (yet)
[03:08] deanlandolt: but i keep postponing finishing my couch store for perstore -- i've got a store wrapper that listens on the couch _changes feed and will update sql or mongo
[03:08] isaacs: neato
[03:08] mikeal has joined the channel
[03:08] amerine has joined the channel
[03:08] binary42 has joined the channel
[03:09] deanlandolt: so you can have couchapps do what they do but progressively enhance your apps w/ multi-faceted or fulltext search
[03:09] deanlandolt: but  yeah, flusspferd should work w/ juice -- but i can't make any promises :)
[03:10] deanlandolt: i'm only promising it'll work on raw node and narwhal/rhino -- but it should be easier with krisk's narwhal/node engine
[03:21] PyroPete1 has joined the channel
[03:23] saikat has joined the channel
[03:24] bmizerany has joined the channel
[03:31] mikeal has joined the channel
[03:37] creationix has joined the channel
[03:41] isaacs has joined the channel
[03:47] sh1mmer has joined the channel
[03:47] colin__ has joined the channel
[03:48] dgathright has joined the channel
[03:51] BinaryPie has joined the channel
[03:54] andrewvc: I'm trying to use a Buffer for a response, but I keep getting the error: node http server: TypeError: Second argument should be a buffer when I call response.end(buffer), any ideas? I'm using the sample code from some of ry's slides
[03:55] andrewvc: I tried providing the buffer as the second arg, and the docs say nothing. And you can't response.write a buffer, so what am I missing?
[03:58] creationix: andrewvc: are you sure your data is a buffer?
[04:01] bpot has joined the channel
[04:04] creationix: andrewvc: I use buffers and end() in wheat, you can look at my code to see an example that works (http://github.com/creationix/wheat)
[04:04] keeto has joined the channel
[04:06] andrewvc: thanks, I actually just figured it out, I was being a bonehead
[04:06] andrewvc: thanks though
[04:06] andrewvc: to answer your question, it wasn't a buffer I was doing buf = buffer.write for some reason I cannot fathom
[04:08] creationix: that will do it
[04:14] quirkey has joined the channel
[04:15] jansc has joined the channel
[04:16] cruxst has joined the channel
[04:17] tlrobinson_ has joined the channel
[04:27] brainproxy: two mentions of node in the top 20 of hackernews :)
[04:30] JimBastard_ has joined the channel
[04:31] JimBastard_: yo ry_ i just monkey punched the shit out of http.createServer and it felt good
[04:31] JimBastard_: creationix helped ^_^
[04:31] JimBastard_: module cache ftw
[04:32] creationix: ok, I think I know what's killing howtonode, my child processes are never closing their file descriptors
[04:32] creationix: and eventually I run out
[04:32] creationix: will lsof show this kind of stuff?
[04:32] JimBastard_: that will do it
[04:34] creationix: I'm in Linux btw
[04:35] creationix: hmm, gnome system monitor has an "open files" option for each process...
[04:36] sudoer has joined the channel
[04:38] Dethe has joined the channel
[04:38] markwubben has joined the channel
[04:38] creationix: hmm, nothing interesting
[04:42] bolson has joined the channel
[04:42] keeto has joined the channel
[04:51] mattly has joined the channel
[05:01] boaz has joined the channel
[05:04] noonat has joined the channel
[05:10] Tim_Smart has joined the channel
[05:12] JimBastard_: iits Tim_Smart !
[05:12] JimBastard_: :-D
[05:12] Tim_Smart: orly
[05:13] boaz has joined the channel
[05:22] mikeal has joined the channel
[05:23] JimBastard_: sup mikeal 
[05:23] mikeal: not much
[05:24] JimBastard_: you see that blog post today about doing http proxies in node?
[05:24] mikeal: nope
[05:24] mikeal: link?
[05:24] JimBastard_: http://catonmat.net/http-proxy-in-nodejs
[05:25] JimBastard_: pretty much exactly the same stuff
[05:25] JimBastard_: just kinda funny
[05:26] mikeal: haha,
[05:26] mikeal: this dramatic realization is what happened to me last September :)
[05:26] bolson has joined the channel
[05:26] JimBastard_: fun to watch
[05:26] JimBastard_: knowledge spread
[05:26] mikeal: totally
[05:27] felixge has joined the channel
[05:27] felixge has joined the channel
[05:27] dekz has joined the channel
[05:27] mikeal: the sad thing
[05:27] mikeal: is that all i see are the problems with this code
[05:28] mikeal: it's doing ascii conversion for all the buffers it's writing
[05:28] mikeal: it doesn't workaround the current HEAD bug
[05:28] mikeal: it doesn't pool clients
[05:28] bolson has left the channel
[05:28] mikeal: it's still faster and simpler than anything you could write in Python tho
[05:28] bolson has joined the channel
[05:30] _ry: mikeal: i fixed issue 77
[05:30] mikeal: awesome!
[05:31] _ry: just putting together a nice diff
[05:32] mikeal: cool
[05:33] mikeal: i'll check it out in the morning once it's checked in
[05:50] amerine has joined the channel
[06:03] Ned__: anyone know a good IRC client library ?
[06:11] andrewvc has joined the channel
[06:11] tekky has joined the channel
[06:17] sudoer has joined the channel
[06:20] keeto has joined the channel
[06:20] bolson has joined the channel
[06:26] siculars has joined the channel
[06:28] mjijackson_ has joined the channel
[06:29] jansc has joined the channel
[06:29] CIA-75: node: 03Ryan Dahl 07master * rf919216 10/ (4 files): 
[06:29] CIA-75: node: Upgrade http-parser, fixes issue 77
[06:29] CIA-75: node: http://github.com/ry/node/issues#issue/77 - http://bit.ly/9STeRX
[06:34] admc has joined the channel
[06:38] towski has joined the channel
[06:40] ahc has joined the channel
[06:40] N` has joined the channel
[06:41] felixge: _ry: are you sure HEAD is broken?
[06:41] felixge: I'm using it and it seems to work
[06:42] felixge: (HTTP HEAD that is)
[06:47] piranha has joined the channel
[06:51] _ry: felixge: you have to have it return a content length
[06:51] _ry: then it will be broken
[06:51] felixge: _ry: ah ok
[06:51] _ry: (or Transfer-Encoding: chunked)
[06:51] felixge: _ry: seems like Amazon S3 was nice to me :)
[06:52] _ry: how so?
[06:52] _ry: oh when doing head requests?
[06:53] Aria: Man, the talk on the commonjs list makes me want to just implement async IO for the other major JS engines.
[06:56] Aria: Anyway. Night!
[06:57] derbumi has joined the channel
[06:58] felixge: _ry: yes
[06:59] felixge: _ry: I have an integration test for our /s3/store robot which checks if a file was uploaded
[07:00] _ry: anyway i have the http-parser fix
[07:01] _ry: just need to hack it into http.js
[07:01] _ry: but things are never done until they're done :P
[07:04] mikeal has joined the channel
[07:09] SamuraiJack has joined the channel
[07:11] _ry: fixed the solaris build bot too :>
[07:11] pedro has joined the channel
[07:13] felixge: :)
[07:13] felixge: ACTION is very excited about 0.2
[07:13] felixge: it feels like 1.0 :)
[07:25] dekroning has joined the channel
[07:26] Azeroth has joined the channel
[07:38] zol has joined the channel
[07:43] tlrobinson_ has joined the channel
[07:43] pdelgallego has joined the channel
[07:45] derbumi has joined the channel
[07:51] drostie has joined the channel
[07:51] teemow has joined the channel
[07:52] sveimac has joined the channel
[07:53] javajunky has joined the channel
[07:54] melgray has joined the channel
[07:54] TomY has joined the channel
[08:14] enherit has joined the channel
[08:15] Nohryb has joined the channel
[08:17] felixge has joined the channel
[08:17] felixge has joined the channel
[08:18] dgathright has joined the channel
[08:18] micheil: _ry: re the status message, do you want patches for what's able to be done?
[08:19] _ry: micheil: ?
[08:20] micheil: for example the emitter for upgrade, that's an easy patch, do you want a patch?
[08:20] _ry: yeah i think so
[08:20] _ry: although i just had some new thoughts about that today
[08:21] _ry: let me email you or catch you on irc in the morning
[08:21] micheil: okay, I'll leave it to you unless you'd like to divulge thoughts?
[08:21] _ry: heading to bed now
[08:21] micheil: okay
[08:21] micheil: night'
[08:21] _ry: night
[08:22] N` has joined the channel
[08:24] zomgbie has joined the channel
[08:25] xla has joined the channel
[08:28] trochala has joined the channel
[08:39] romainhuet has joined the channel
[08:47] ditesh|cassini has joined the channel
[08:50] ewdafa has joined the channel
[09:01] tbassetto has joined the channel
[09:10] tbassetto has joined the channel
[09:17] NickP: 5
[09:20] felixge_ has joined the channel
[09:24] demolithion has joined the channel
[09:42] CodeOfficer has joined the channel
[09:44] felixge has joined the channel
[09:44] felixge has joined the channel
[09:48] botanicus has joined the channel
[09:53] botanicu_ has joined the channel
[09:57] MattJ has joined the channel
[09:59] KungFuHamster_ has joined the channel
[09:59] cruxst has joined the channel
[10:01] bolson has joined the channel
[10:06] vvsh has joined the channel
[10:13] botanicus has joined the channel
[10:39] hellp has joined the channel
[10:44] chakrit has joined the channel
[10:48] pedro has joined the channel
[10:57] botanicus has joined the channel
[10:58] N` has joined the channel
[11:17] jetienne_ has joined the channel
[11:18] jetienne_: q. just compiled node.js, how can i run a exmaple to play with ?
[11:23] jetienne_: $ time curl http://127.0.0.1:8000
[11:23] jetienne_: Hello World
[11:23] jetienne_: real	0m2.052s
[11:23] jetienne_: user	0m0.016s
[11:23] jetienne_: sys	0m0.012s
[11:23] jetienne_: hue ? how come every request is 2sec long
[11:25] jetienne_ has joined the channel
[11:27] shrughes: jetienne_: the code is written to wait for two seconds before replying
[11:27] shrughes: in that particular example
[11:27] jetienne_: shrughes: duh, silly me :)
[11:34] polo has joined the channel
[11:44] jetienne_: Hello world on node.js: 866req/s, on ruby thin: 525req/s <- nice
[11:50] javajunky: jetienne_ : http://tjholowaychuk.com/post/543953703/express-vs-sinatra-benchmarks
[11:53] jetienne_: javajunky: thanks
[12:04] jetienne_: q. is there something similar to script/console from rails ? or simply irb in ruby
[12:06] aho has joined the channel
[12:10] jetienne_: node-repl found
[12:16] jetienne_: impressive work you guys did there, thanks
[12:16] ncb000gt has joined the channel
[12:17] jetienne_: repl could use autocomplete
[12:18] ncb000gt: auto or tab?
[12:18] jetienne_: ncb000gt: not sure, like i press tab and i got the various possibilities presented to me
[12:18] jetienne_: ncb000gt: like bash and file path
[12:19] ncb000gt: yea, that's what i was talking about
[12:19] ncb000gt: auto to me suggests "magic" whereas tab is cause->action
[12:20] ncb000gt: but, i agree it'd be nice to have
[12:20] ncb000gt: I use tab complete with nearly everything just hopping it'll work. :)
[12:21] jetienne_: ok
[12:24] jetienne_: :)
[12:34] Nohryb:  
[12:35] N` has joined the channel
[12:37] boaz has joined the channel
[12:42] javajunky: the issue as I understand it (when I tried to get a similar thing working with kiwi.js) was that stdio only offered data on linebreaks , which made tab completion rather tricky, I've not checked back in since the new buffers stuff to see whether we can intercept on key presses or not.
[12:43] javajunky: (by which I mean node's stdio accessor)
[12:47] chakrit has joined the channel
[12:57] noonat has joined the channel
[13:04] jetienne has joined the channel
[13:07] Dethe has joined the channel
[13:08] kriszyp has joined the channel
[13:12] jetienne has joined the channel
[13:13] jetienne: q. what is the webserver behind node ? it is faster than apache static file delivery
[13:14] boaz has joined the channel
[13:15] ncb000gt: jetienne: there isn't a specific webserver...there are tools that allow people to create webservers
[13:16] ncb000gt: there are some convenience apis available to help in writing a webserver
[13:16] jetienne: ncb000gt: well node blabal.js is doing web services
[13:16] ncb000gt: sure
[13:16] jetienne: ncb000gt: is that a custom one ?
[13:16] chakrit: jetienne there's no web server, you build a networked program that acts like one.
[13:16] ncb000gt: but it would be the thing implementing them
[13:16] jetienne: oh ok i got it
[13:16] ncb000gt: there are a handful of services available
[13:16] ncb000gt: hold on i'll try to find the link
[13:16] jetienne: this is a networked library and this is the example who is doing the web services
[13:17] ncb000gt: http://wiki.github.com/ry/node/modules
[13:17] jetienne: how much of node.js is written in javascript itself ?
[13:17] ncb000gt: not sure in terms of exact numbers or %
[13:18] ncb000gt: but there is a decent amount
[13:18] chakrit: doesn't github have stats?
[13:18] chakrit: http://github.com/ry/node/graphs/languages
[13:19] davidsklar has joined the channel
[13:19] ncb000gt: mmm, good call chakrit.
[13:19] chakrit: :)
[13:20] chakrit: python is used mostly for the builds ... not sure why there's ruby and scheme in there though
[13:21] jetienne: ncb000gt: like > 50% ?
[13:21] jetienne has joined the channel
[13:22] ncb000gt: jetienne: if you look at the link that chakrit posted, you'll see the breakdown of the languages
[13:23] jetienne: ncb000gt: my modem is broken, i miss chakrit link. can you give it ?
[13:23] ncb000gt: http://github.com/ry/node/graphs/languages
[13:23] mythz has joined the channel
[13:25] N` has joined the channel
[13:25] robrighter has joined the channel
[13:27] polo has joined the channel
[13:27] jetienne: ncb000gt: but this stats include v8, correct ?
[13:28] ncb000gt: jettienne: correct
[13:28] byoteki has joined the channel
[13:28] jherdman has joined the channel
[13:28] ncb000gt: I'd say that node itself is probably half C++ and half JS
[13:29] ncb000gt: with a dash of Python (for builds) and some bash
[13:29] jetienne: ncb000gt: ok thanks
[13:32] zomgbie has joined the channel
[13:37] binary42 has joined the channel
[13:47] aho: jetienne, v8 contains over 400kb of js code though. so, the stats probably aren't as skewed as they might appear initially
[13:49] jetienne has joined the channel
[13:56] siculars has joined the channel
[13:57] zomgbie has joined the channel
[13:59] gf3 has joined the channel
[14:06] thomaslee has joined the channel
[14:10] piranha has joined the channel
[14:13] pgriess has joined the channel
[14:14] Yuffster has joined the channel
[14:15] quirkey has joined the channel
[14:16] nwhite has joined the channel
[14:21] piranha_ has joined the channel
[14:23] tmpvar has joined the channel
[14:24] tmpvar: morning
[14:24] micheil: moni
[14:24] micheil: *moin
[14:24] pedro__ has joined the channel
[14:25] ncb000gt: morning
[14:26] ncb000gt: unfortunately, I'm awake
[14:26] tmpvar: yes.
[14:27] ceej has joined the channel
[14:27] ceej: does anyone have an example of a site running node.js?
[14:27] tmpvar: howtonode.org
[14:27] tmpvar: transload.it
[14:27] micheil: ceej: try dropular.net
[14:28] ceej: thank you both, anyone made an MVC wrapper/lib for it yet like CI for php?
[14:29] tmpvar: CI?
[14:29] ncb000gt: ceej: http://wiki.github.com/ry/node/modules
[14:29] ceej: codeigniter.com
[14:29] micheil: ceej: use it's better cousin: kohana php
[14:29] ncb000gt: people are working on frameworks
[14:30] tmpvar: yeah, most mature im guessing is express
[14:30] tmpvar: but its getting big, fast lol
[14:30] micheil: there's also OUI that powers dropular, and from what I hear rsms is writing an article up on that
[14:30] ncb000gt: tmpvar: i'd agree, so far it's the big one
[14:30] ncb000gt: nice
[14:30] micheil: there's also (fab)
[14:30] micheil: which I still don't understand, :(
[14:30] tmpvar: for routing only though, right?
[14:30] ncb000gt: lol
[14:31] tmpvar: fab, nerve, fu, etc
[14:31] ncb000gt: I'm working on putting together a more dynamic type listing of modules that could also potentially serve as a repository...
[14:31] ncb000gt: just haven't had time to do more work on it the past couple days
[14:32] tmpvar: nice, have you talked to isaacs?
[14:32] ncb000gt: yea a bit, with the npm stuff?
[14:32] tmpvar: from what I understand he was working on a similar thing using couch
[14:32] tmpvar: yeah
[14:32] ncb000gt: it looked nice
[14:32] ncb000gt: and pretty large
[14:32] ncb000gt: err rather, it looked like he'd taken care of a lot of things
[14:32] tmpvar: yeah
[14:32] ceej: node.js seems very interesting.... so can you assign a session to each user where you can push live data to them?  like you can do with ape-project.org?
[14:33] ncb000gt: ape uses comet yea?
[14:33] ceej: yep
[14:33] ncb000gt: yea it looks like it does, you can use websockets, xmpp, etc with node
[14:34] ncb000gt: it is really just platform and you write the extras on top
[14:34] ncb000gt: or people write frameworks and others use em
[14:35] softdrink has joined the channel
[14:36] ceej: are there any bench marks against apache/php?
[14:37] herby_sk has joined the channel
[14:38] kriszyp has joined the channel
[14:40] tmpvar: umm
[14:40] tmpvar: there are somewhere, where? unsure
[14:40] ditesh|cassini has joined the channel
[14:41] ncb000gt: if you look at _ry's talk at jsconf.eu you'll see some benchmarks against apache
[14:41] ncb000gt: in terms of requests and in terms of resources
[14:41] ncb000gt: also, he gave a talk at jsconf.us/2010 with more benchmarks
[14:42] mape: http://www.apple.com/hotnews/thoughts-on-flash/ javascript on the rise ;)
[14:42] ncb000gt: but those were more focused towards other async frameworks iirc
[14:42] ncb000gt: tornado, and others
[14:42] ncb000gt: I don't remember where that pdf is at
[14:42] mape: nodejs.org/jsconf.pdf
[14:43] mape: http://nodejs.org/jsconf2010.pdf
[14:43] mape: even
[14:43] mape: the other one was old
[14:43] ceej: thank you i'll check it out
[14:44] quirkey has joined the channel
[14:44] jetienne_ has joined the channel
[14:46] ncb000gt: ty mape :)
[14:51] mjijackson has joined the channel
[14:52] ditesh|cassini has joined the channel
[14:54] gwoo has joined the channel
[14:54] colin___ has joined the channel
[15:08] alex-desktop has joined the channel
[15:12] mikeal has joined the channel
[15:14] creationix has joined the channel
[15:14] tmpvar: hey there creationix
[15:14] creationix: hey
[15:22] devinus has joined the channel
[15:23] jedschmidt has joined the channel
[15:26] sudoer has joined the channel
[15:28] N` has joined the channel
[15:29] brianmario has joined the channel
[15:30] steadicat has joined the channel
[15:32] vvsh has joined the channel
[15:37] tlrobinson_ has joined the channel
[15:45] tmpvar has joined the channel
[15:47] N` has joined the channel
[15:51] mjr_ has joined the channel
[15:56] dgathright has joined the channel
[15:58] mattly has joined the channel
[16:02] Dethe has joined the channel
[16:08] _ry: Challenge: show an erlang webserver response faster than node
[16:09] _ry: s/response/respond/
[16:10] mjr_: _ry: it looks like you had a nice, intimate evening with issue 77.
[16:10] _ry: not having your own bulky scheduler has its advantages
[16:10] _ry: advantages = i'll own erlang in nearly any benchmark
[16:10] amerine has joined the channel
[16:10] _ry: (having v8 doesn't hurt too ;))
[16:11] _ry: mjr_: yeah i wasn't able to see the problem due to other bugs that got fixed recently
[16:11] _ry: but it was just some http-parser issue
[16:11] mjr_: either way: win
[16:12] _ry: mjr_: is it working for you?
[16:12] pavelz has joined the channel
[16:13] noonat has joined the channel
[16:14] _ry: (not that i suggest node is a viaable alternative to erlang)
[16:14] javajunky1 has joined the channel
[16:14] mjr_: I haven't tried it yet.  I probably won't have time for the next couple of days.  People are actually using our software now, and buffering is working for the time being. 
[16:15] ayo has joined the channel
[16:17] MattJ: _ry: Not a hard challenge I'd say :)
[16:19] _ry: MattJ: i await your bench :)
[16:19] MattJ: Ha :)
[16:19] _ry: maybe i'm wrong - but i've never been able to get mochiweb to perform well
[16:20] _ry: the fucking thing is just sitting there in the super cool scheduler all the time
[16:21] _ry: and/or churning slowly through BEAM code
[16:22] indiefan has joined the channel
[16:25] bpot has joined the channel
[16:26] devinus: _ry: i still stand by the fact from my work with mochiweb/webmachine that node performs much better
[16:26] devinus: a lot of our back end services are webmachine projects
[16:26] colin__ has joined the channel
[16:30] RayMorgan has joined the channel
[16:31] micheil_away: morning _ry 
[16:31] _ry: micheil_away: hey going to PM you
[16:31] micheil_away: okay
[16:36] javajunky has joined the channel
[16:36] javajunky has joined the channel
[16:39] boaz has joined the channel
[16:43] JAAulde has joined the channel
[16:43] nefD: hrm.. retrieving .text() values from elements (using libxml) results in those strings containing unicode chars (ie: \u2019 and the like).. is there any way to convert those strings back into 'normal' (ansi?) characters?
[16:43] kriszyp_ has joined the channel
[16:44] JAAulde: WHOA! The last build my build slave ran passed--on FreeBSD
[16:44] JAAulde: HOORAY!
[16:46] nefD: wait nm.. i might be dumb
[16:47] nefD: blargh.. i am dump. but that didn't solve anything
[16:49] herbySk has joined the channel
[16:50] micheil_away: what's the first argument on events.EventEmitter?
[16:51] micheil_away: eg,   events.EventEmitter.call(this, socket);
[16:51] micheil_away: when does events.EventEmitter use socket
[16:59] isaacs has joined the channel
[17:03] kriskowal has joined the channel
[17:07] mythz has left the channel
[17:09] Kisama has joined the channel
[17:11] steadicat has joined the channel
[17:12] jedschmidt has joined the channel
[17:15] _ry: JAAulde: rad
[17:16] JAAulde: _ry: indeed!
[17:19] Nohryb_ has joined the channel
[17:19] enherit has joined the channel
[17:20] CodeOfficer has joined the channel
[17:23] _ry: i'm going to release 0.1.93 unless someone objects
[17:24] gwoo: nice
[17:29] lifo has joined the channel
[17:34] Nohryb_ has joined the channel
[17:35] digitalspaghetti has joined the channel
[17:36] mikeal has joined the channel
[17:38] RayMorgan has joined the channel
[17:38] towski has joined the channel
[17:39] Nohryb_ has joined the channel
[17:39] Nohryb__ has joined the channel
[17:39] _ry: mikeal: did 77 get fixed?
[17:40] mikeal: haven't had a chance to check yet
[17:40] mikeal: just got in to the office with my coffee
[17:42] pkrumins: what's new in 0.1.93
[17:42] _ry: pkrumins: git log v0.1.92..HEAD 
[17:42] _ry: :)
[17:42] pkrumins: :)
[17:44] charlesjolley has joined the channel
[17:46] charlesjolley has joined the channel
[17:47] enherit has joined the channel
[17:49] indiefan has joined the channel
[17:50] SamuraiJack: hello
[17:50] SamuraiJack: what will be a reliable way to determine, whether script is running in Node?
[17:51] SamuraiJack: presense of 'global'? or is there something more specific?
[17:51] tmpvar: oh
[17:51] tmpvar: process.argv[0] ?
[17:51] tmpvar: there is also a version prop somewhere
[17:52] SamuraiJack: `process.argv[0]` looks good
[17:52] sh1mmer has joined the channel
[17:52] SamuraiJack: thanks
[17:52] tmpvar: np
[17:52] konobi: SamuraiJack: unless you're using a shebang line
[17:53] SamuraiJack: and what will be if I'll be using it?
[17:53] konobi: whatever the name of your script is
[17:54] SamuraiJack: its ok, in browser it will be undefined
[17:57] dgathright has joined the channel
[17:57] _ry: mikeal: v0.1.93 will be released as soon as you confirm 77 is fixed.
[17:58] mikeal: working on it
[17:58] _ry: ACTION heads into work. bbiab.
[18:01] creationix: konobi: are you sure about that
[18:01] creationix: I thought it returned node even for shebang scripts
[18:01] robrighter_ has joined the channel
[18:01] pedro has joined the channel
[18:07] cloudhead has joined the channel
[18:08] konobi: creationix: SIAS
[18:11] creationix: konobi: yep, it just returns "node" for argv[0] in  "#!/usr/bin/env node" scripts
[18:12] konobi: how about `#!/usr/bin/node`
[18:14] mikeal: _ry: the test is still failing 
[18:14] steadicat_ has joined the channel
[18:17] sh1mmer has joined the channel
[18:21] Guest19576 has joined the channel
[18:24] _ry: mikeal: fuck :/
[18:24] mikeal: did the test pass for you?
[18:25] _ry: i believe so - running it again
[18:25] _ry: (it takes so long)
[18:26] mikeal: it hits
[18:26] mikeal: DEBUG: calling chargen for 100000 chunks.
[18:26] mikeal: within a few seconds
[18:26] mikeal: and then hangs indefinitely
[18:26] mikeal: for me
[18:26] mikeal: oh, there it goes on to the next one
[18:26] mikeal: it's this one that doesn't finish
[18:27] mikeal: DEBUG: calling chargen for 1000000 chunks.
[18:28] _ry: i think it's just spending a long time creating the 20mb of chunks
[18:29] mikeal: the first thing i did was try replicating through my proxy, and that acted the same as it always has
[18:29] mikeal: no change
[18:30] _ry: ok
[18:30] mikeal: but i wanted to run this test to make sure because it's a more isolated bit of code
[18:30] _ry: yeah okay
[18:31] mjr_ has joined the channel
[18:34] SamuraiJack: how I can add a new module to the built-in ones?
[18:34] SamuraiJack: so it will be available each time node starts?
[18:35] _ry: SamuraiJack: put it in lib/ and look in src/node.cc to see how, for example http is included
[18:36] admc has joined the channel
[18:36] mjr_: At first I thought compiling in lib was madness, but then I got like 3 different versions of node running at the same time.
[18:36] fizx has joined the channel
[18:36] mjr_: Now it seems pretty brilliant.
[18:36] SamuraiJack: and then recompile?
[18:36] ncb000gt: lol
[18:37] _ry: SamuraiJack: yes
[18:37] SamuraiJack: ok, thanks
[18:38] _ry: it's nice to have everything in one place
[18:38] RayMorgan: _ry: is there anyway or any plans to be able to read data from a file/socket directly to a buffer to avoid a V8 string?
[18:38] _ry: RayMorgan: yes - it needs ot happen
[18:38] RayMorgan: sweet
[18:39] _ry: yeah i think this test/disabled/test-http-big-pr
[18:39] _ry: oxy-responses.js
[18:39] _ry: is a really nice test
[18:39] _ry: if i dtrace it in the 1000000 chunk case - i see many writes
[18:39] creationix has joined the channel
[18:39] _ry: but each write it only one chunk
[18:40] _ry: s/it/is/
[18:40] _ry: clearly it's doing something wrong
[18:40] _ry: additionally memory usage keeps increasing when it should be decreasing
[18:41] _ry: which makes me thing the GC idle thing needs to be more aggressive
[18:41] mjr_: does it actually go down if you have enough idle time for GC, or is it leaking?
[18:41] _ry: not sure
[18:42] _ry: i've noticed in recent releases the node_chat is using lots more memory 
[18:42] _ry: i'm a bit worried we're leaking somewhere
[18:43] mjr_: I was seeing that before 1.90, but it seems to be pretty stable for me.
[18:43] mjr_: mjr       6311  0.0  1.0  65068 18792 ?        Sl   Apr23   9:25 /usr/local/bin/node
[18:43] mjr_: That's after proxying 1M requests since the 23rd.
[18:43] _ry: i use to idle around 8mb rss - now i'm idling at 17mb
[18:43] _ry: (after a few days)
[18:44] mjr_: Oh, interesting.
[18:44] _ry: it might be fragmentation
[18:44] mjr_: I used to have a steady climb, but something around 1.90 seems to have fixed that.
[18:45] pedro has joined the channel
[18:45] _ry: man there is something seriously broken in how that proxy test is pushing data...
[18:45] _ry: this can't be attributed to v8 string suck
[18:45] mjr_: I'm also at 17MB, but I'm fine with that since it is stable.
[18:46] mikeal: well, rnewson wrote that pretty quickly, there is probably a better way to do this test
[18:46] _ry: yeah - i mean - it's pretty hacky
[18:46] _ry: but still i think it's okay
[18:46] _ry: i modified it a bit
[18:47] mikeal: the loop that does the writes is blocking while it finishes all the writes
[18:47] _ry: yeah
[18:47] mikeal: we should do that in a setTimeout()
[18:47] _ry: nah, it's okay
[18:47] _ry: i mean i think in real life you would try to do throttling and stuff 
[18:48] _ry: but just filling the buffer up with 200mb of data
[18:48] _ry: and watch it drain
[18:48] _ry: it's a good test
[18:48] mikeal: i guess it's a good test in that it tests a bunch of stuff
[18:48] mikeal: but a bad test for the same reason
[18:48] _ry: yeah - so it used to not finish
[18:48] _ry: then we got a fix to net.js
[18:48] _ry: and then it had a Parse Error
[18:48] mikeal: it never finishes for me
[18:48] _ry: then i fixed a bug last night
[18:49] _ry: and now it's churning very slowly
[18:49] mikeal: i'm gonna add some debugging in to my proxy
[18:49] mikeal: and then do replication
[18:49] mikeal: and tell you if I'm getting an "end"
[18:49] mikeal: event
[18:49] _ry: write(0x10, "14\r\n01234567890123456789\r\n\0", 0x1A)            = 26 0
[18:49] _ry: ^-- this is what it's doing
[18:49] _ry: a lot of write() calsl
[18:49] _ry: one per chunk
[18:50] _ry: but if it has all that stuff in the buffer - ideally it'd do fewer write() calls and chunk the chunks together
[18:51] mjr_: Yeah, that would be a huge win to re-chunk.
[18:51] rictic has joined the channel
[18:51] mjr_: maybe not huge, but it would be good to do.
[18:56] mikeal: oh cool
[18:56] _ry: boom
[18:56] _ry: fixed it :)
[18:56] mikeal: I am getting an end event now on this long _changes feed
[18:56] _ry: (did i just say 'boom'?)
[18:57] mikeal: yes you did :)
[18:57] mikeal: <ry> boom
[18:57] mikeal: :P
[18:57] _ry: *shame*
[18:57] mjr_: Next thing you know, _ry will point out something good about OSX.
[18:57] dgathright_ has joined the channel
[18:57] mjr_: since apparently he's channeling Steve Jobs.
[18:57] mape: node scrolls like butter
[18:57] mikeal: <_ry> and it's fantastic 
[18:59] _ry: chunking those stirngs together made a big difference
[19:00] mikeal: the first graph you have where node is faster than nginx
[19:00] mikeal: i expect you to yell "boom!"
[19:00] binary42 has joined the channel
[19:01] CIA-75: node: 03Ryan Dahl 07master * rc75e4cb 10/ doc/api.markdown : fix typos - http://bit.ly/9QPwWX
[19:01] CIA-75: node: 03Ryan Dahl 07master * r301b44d 10/ (lib/net.js test/disabled/test-http-big-proxy-responses.js): Chunk strings together on Stream buffer - http://bit.ly/cRor5c
[19:01] _ry: it was even a TODO 
[19:02] nefD: after an upgrade of node, is it neccesary to rebuild any modules which require a node-waf build?
[19:02] _ry: nefD: not usually
[19:02] maushu has joined the channel
[19:02] nefD: _ry:  Gotcha.. thanks.. I'm guessing if it is, it'll be somewhat apparent after trying to use any offending modules :)
[19:03] _ry: mikeal: so try 301b44d with your couchdb thing
[19:03] mikeal: these dots you added to the test make me feel much saner while i'm watching the terminal
[19:03] TobiasFar has joined the channel
[19:06] quirkey_ has joined the channel
[19:07] Digem has joined the channel
[19:17] towski has joined the channel
[19:26] jedschmidt has joined the channel
[19:27] pdelgallego has joined the channel
[19:33] maushu has joined the channel
[19:39] hsuh has joined the channel
[19:43] javajunky has joined the channel
[19:58] tilgovi has joined the channel
[20:00] qFox has joined the channel
[20:00] qFxo has joined the channel
[20:02] bmizerany has joined the channel
[20:02] quirkey has joined the channel
[20:08] sh1mmer has joined the channel
[20:12] jansc has joined the channel
[20:13] duke_ has joined the channel
[20:14] herbySk has joined the channel
[20:18] indiefan has joined the channel
[20:18] ashiso has joined the channel
[20:22] tmpvar has joined the channel
[20:27] bmizerany has joined the channel
[20:30] thorat has joined the channel
[20:34] _ry: feeling the need for a low water mark
[20:34] mattly has joined the channel
[20:35] hellp has joined the channel
[20:35] kriskowal: _ry from the control theory perspective, it would be better to just be able to query the length of the buffer
[20:37] _ry: ?
[20:40] kriskowal: you probably know more about control theory than i do, but at fastsoft we regulate the tcp congestion window based on observations to changes in the round trip time, which ultimately comes from the length of queues on the bottleneck router
[20:41] mikeal: that's smart
[20:41] mikeal: mobile routers keep big ass queues, so TCP will just keep pushing at them until it sees loss
[20:41] mikeal: regulating it based on the round trip time solves that 
[20:41] _ry: kriskowal: i'm at a much more primative level
[20:41] _ry: i'm just trying to not make syscalls ever 5 bytes
[20:42] _ry: (it's sad that this is state of the art  ;))
[20:42] _ry: but i think i just figured it out - the problem in this proxy is that the chunks come in as Buffer
[20:42] romainhuet has joined the channel
[20:42] _ry: but the 14\r\n (length) and "\r\n" boundaries 
[20:43] _ry: for the message (strings)
[20:43] _ry: are written as strings
[20:43] _ry: my algorithm doesn't chunk them together
[20:43] _ry: so i'm getting all these syscalls with write(fd, "\r\n")
[20:43] _ry: which is dumb
[20:43] pjb3 has joined the channel
[20:44] _ry: i have this large "pool" buffer
[20:44] _ry: so i'm going to try filling it up with everything in the socket's queue
[20:44] _ry: then try to write it out with one syscall
[20:44] _ry: "range" out the rest
[20:44] kriskowal: ah, good
[20:45] _ry: that should avoid these little write("\r\n") things that are killing performance
[20:45] RayMorgan has joined the channel
[20:45] _ry: i've got nagel on - so i think the packets aren't actually so small
[20:45] _ry: but each syscall is something like 300 cycles at least
[20:46] mjijackson has joined the channel
[20:46] _ry: net.js is so great in that i can try out all these algorithms
[20:46] _ry: in evcom trying this out would take me a month
[20:47] mikeal: after you finish that
[20:47] mikeal: i want to see another graph that compares against nginx :)
[20:48] _ry: it's not going to improve the nginx / node 'ehllo world' benchmark
[20:48] _ry: because in that i was very careful to do just one syscall
[20:48] _ry: but in this proxy example it falls apart
[20:48] mikeal: what i actually want to see is file serving performance
[20:49] mikeal: across concurrent connections
[20:49] _ry: let me make this change - then we'll fire up paperboy
[20:49] _ry: well
[20:49] _ry: fs.read isn't doing buffers
[20:49] _ry: whcih hurts
[20:49] _ry: got to get fs.read to pull in a single buffer
[20:50] _ry: then sending it to socket will be nothing
[20:50] _ry: i'm starting to think - let's just replace the entire stack with a node process
[20:50] _ry: well and some sort of db
[20:51] _ry: but there might be little point in having an nginx load balance across multiple nodes
[20:51] mikeal: just let the kernel do that
[20:51] _ry: or just use one :)
[20:51] _ry: i think that will work for most cases
[20:51] mikeal: you can tell it to round robin requests to one port to a bunch of ports
[20:51] mikeal: one node process per core 
[20:51] mikeal: on a different port
[20:51] charlesjolley has joined the channel
[20:52] mikeal: i want nginx/apache out of the stack
[20:52] _ry: i think getting paperboy to match nginx static file serving speeds should be doable
[20:52] mikeal: they shouldn't be necessary at least
[20:52] mikeal: even CouchDB is trying to run on port 80 with nothing in between
[20:52] _ry: the memory usage is going to be much different of course
[20:53] _ry: nginx is like 2mb footprint at any load
[20:53] mikeal: memory is cheap, all i care about is concurrent performance
[20:53] sh1mmer has joined the channel
[20:53] javajunky: _ry : this is possibly a stupid question, but is it currently possible for me to create a https (client) request to a https server ..I can find in the test examples of https servers, and creating ssl socket connections … do I just need to plug things together and provide the certificates in the right place in teh code ? (sorry)
[20:53] mikeal: if average request times for a couple thousand concurrent connections drops 20% and it uses 200megs of memory, who cares
[20:54] mikeal: javajunky: you've gotta use the crypto library
[20:54] mikeal: someone had a gist example
[20:54] WALoeIII has joined the channel
[20:55] javajunky: post the ssl merge ?
[20:55] javajunky: (sorry that was unclear, mikeal: even after the ssl merge ? ) 
[20:56] mikeal: as far as i know, yes
[20:56] kjeldahl_ has joined the channel
[20:56] mikeal: crypto still isnt' documented :(
[20:57] _ry: yeah
[20:57] javajunky: ahhh sweet so _ry did expose the ssl api in the end ?
[20:58] javajunky: that would be freakin' awesome if I can ditch my javascript implementations of the digest algorithms :)
[20:59] _ry: javajunky: no secure http client right now
[20:59] _ry: :
[20:59] _ry: which i've forgotten about
[20:59] mikeal: i have code somewhere that works
[20:59] mikeal: that uses crypto
[20:59] mikeal: i had to generate a cert and all that annoying crap tho
[20:59] mikeal: and brew install pkg-config
[21:00] mikeal: so that node would install openssl
[21:00] _ry: we're going to have node come with all the root CAs soon
[21:01] javajunky: _ry: no worries :)  
[21:01] _ry: so it should be much easier in the next few weeks
[21:01] javajunky: _ry: I saw on the mailing list, the mozilla certs 
[21:01] tmpvar has joined the channel
[21:01] javajunky: _ry: hmm on what you just said does that mean that the presence of https will be specific to each node environment, i.e. sometimes it will be available othertimes not ?
[21:01] mjr_: I can write up some docs for ssl, but it seemed like that stuff was a bit early and likely to change.
[21:02] javajunky: mjr_ : I'd be interested in just a block of working code I can back-figure from there no worries :)  
[21:03] _ry: javajunky: test/disabled/test_tls*
[21:03] _ry: javajunky: test/disabled/tls*
[21:04] _ry: test/simple/test-http-tls.js
[21:06] mape: Anyone here had issues getting the mongodb module to work on a 64bit system?
[21:06] javajunky: _ry : I've looked through that, I guess that was my original question (or more accurately what I meant, doh!) .. currently I'll need to manage the HTTP protocol myself  .. I think you've confirmed that for me (and said support is coming <g> )  :)
[21:06] javajunky: mape: nope.
[21:06] mape: Getting /usr/bin/ld: /home/mape/.node_libraries/node-mongodb/mongo-c-driver/libmongoc.a(mongo.o): relocation R_X86_64_32 against `.rodata.str1.1' can not be used when making a shared object; recompile with -fPIC
[21:06] javajunky: mape: which mongodb actually
[21:06] _ry: javajunky: try the http.Client in the same way that net.Stream is done
[21:06] javajunky: ah yeah no I use the 'native' one.
[21:07] _ry: it is a subclass
[21:07] mape: javajunky: Url? :)
[21:07] _ry: i just don't have a test showing it works
[21:07] _ry: but i think it should
[21:07] _ry: mjr_: can you confirm?
[21:07] javajunky: _ry .. I'll give it a shot if it works do you want a test ?
[21:07] _ry: javajunky: sure
[21:07] mjr_: just looking at those tests now
[21:08] javajunky: mape: kiwi install mongodb-native 
[21:08] javajunky: mape: or.. http://github.com/christkv/node-mongodb-native :)
[21:08] javajunky: mape: also there's a session plugin for express that works over it . (express-session-mongodb)
[21:08] mape: ah ncie
[21:13] indexzero has joined the channel
[21:16] ryan[WIN]: hey quick thing on the nodejs docs
[21:17] ryan[WIN]: on the fs.writefile example 
[21:17] ryan[WIN]:   sys.puts('It's saved!');
[21:17] ncb000gt has left the channel
[21:17] ryan[WIN]: i probably don't need to go into depth on why that's wrong
[21:17] mjr_: I think _ry just pushed a fix for that
[21:17] ryan[WIN]: o
[21:17] ssteinerX has joined the channel
[21:17] mjr_: I had that fix in my next doc update though.
[21:17] mjr_: Just working through the fs parts.
[21:20] RayMorgan has joined the channel
[21:26] jedschmidt has joined the channel
[21:29] mjr_: javajunky: did you get your https client working?
[21:31] javajunky: mjr_ I appear to be struggling with the basics atm ;) 
[21:31] javajunky: the test doesn't seem to be executing my code to give me errors even, working through it though
[21:34] mattly has joined the channel
[21:34] javajunky: ooooo getting somewhere.
[21:41] mjr_: I got it doing something, not happy with HTTP, and now I have to go do real work.
[21:41] teemow has joined the channel
[21:41] byoteki has left the channel
[21:41] mjr_: but it does seem to be doing ssl-ish stuff.
[21:42] mikeal: mjr_: you saw that issue 77 is fixed right :)
[21:42] mjr_: I did.  Big news.
[21:42] mikeal: you should come down for drinks tomorrow
[21:42] mikeal: we'll celebrate :)
[21:42] mjr_: Too bad you wrote your own erlang thing.
[21:42] mjr_: I'd love to come tomorrow, but I'm going on a family camping trip.
[21:42] mikeal: it kinda rocks tho
[21:42] mjr_: taking the day off, etc.
[21:43] javajunky: mjr_: yeah createClient takes a load of new handy parameters..   s'kinda working.. doesn't appear to be verifying anything as yet.. 
[21:44] boaz has joined the channel
[21:44] justinlilly has joined the channel
[21:46] pedro has joined the channel
[21:49] javajunky: mjr_: hmm it looks like its mostly there, but there's no verification hook exposed that I can see 
[21:52] mattly has joined the channel
[21:56] drostie has joined the channel
[21:56] bluergh has joined the channel
[21:57] bluergh: Hey, can anyone point me in the direction of a downloadable form of the documentation?
[21:57] bluergh: for http://nodejs.org/api.html
[21:58] _ry: bluergh: http://s3.amazonaws.com/four.livejournal/20100429/node_doc.pdf
[21:59] bluergh: cool thanks, also looks like it's in the git repo
[21:59] bluergh: should look before asking next time :)
[22:00] kriskowal_ has joined the channel
[22:01] rolfb has joined the channel
[22:02] mjr_: Yeah, I guess mape's fancy doc viewer doesn't print very well.
[22:02] mjr_: I figure it would, but on my machine it only prints the first page.  Whoops.
[22:03] mape: Never really though about that
[22:03] mape: but should be easy enough if you for some reason would like to print the docs
[22:03] mjr_: me either.  It usually ends up looking OK.
[22:03] mjr_: In Safari on my machine I only end up with the first page.
[22:05] mape: Yeah that is because the sticky menu
[22:05] mape: but you could just change the menu to fixed and the content to static with margin left
[22:05] mjr_: and maybe even do some CSS thing so that when you print it the left menu goes away completely.
[22:06] mape: yeah
[22:06] mjr_: Also, isn't printing quaint?
[22:07] mape: Well I don't see a lot of people doing it
[22:07] creationix has joined the channel
[22:08] kriskowal has joined the channel
[22:09] dgathright_ has joined the channel
[22:15] gwoo has joined the channel
[22:19] darkf has joined the channel
[22:21] javajunky: uggh frustratingly close to having a working https client configuration! 
[22:23] dekz has joined the channel
[22:24] tmpvar has joined the channel
[22:24] javajunky: yay it works!
[22:27] mape: :)
[22:28] mjr_: Can you paste the code somewhere?
[22:30] javajunky: https://gist.github.com/f7d99e5ac8f289551191
[22:30] javajunky: yup :)
[22:31] javajunky: mjr_ I imagine I've done somethign wrong, but hell amazingly it seems to work .. just about to check the traffic is really encrypted ;)
[22:32] plhw_ has joined the channel
[22:32] mape: javajunky: do you really need to assign the cert?
[22:32] plhw_: Hi
[22:32] ceej has joined the channel
[22:32] creationix has joined the channel
[22:32] javajunky: mape: yeah I think so at the moment, as there's no 'shared web of trust' root CAs inside of node, (and anyway I self-signed) .. but that could be wrong ?
[22:33] javajunky: I only needed that to make sure it was a 'verified' connection.
[22:33] mape: javajunky: http://github.com/mape/node-prowl/blob/master/lib/prowl.js
[22:33] mape: thats a module I made some time ago, connects to a https and POST data
[22:33] mape: didn't need the cert at all
[22:34] mape: works in v0.1.92-36-g301b44d
[22:36] javajunky: you're right as long as I don't care about it being verified its still a 'secured' connection
[22:37] javajunky: also where were you when I was asking if this was even possible !!!! 
[22:37] bmizerany has joined the channel
[22:37] freshtonic has joined the channel
[22:37] mjr_: so I guess you don't even need the CA public keys?
[22:38] mjr_: or whatever they are called in x.509 speak
[22:38] javajunky: well you can supply them yourself, but it would be easier if node had them by default
[22:38] javajunky: without the CA public keys or specifying them yourself there's no way of 'authenticating/trusting' the remote host is who they're saying they are..
[22:38] javajunky: as Iunderstand it (loosely)
[22:38] mjr_: sure, but apparently the openssl library is OK with that?
[22:39] javajunky: it would seem so :)
[22:39] mape: javajunky: hehe I thought you were talking about something more advance then what I had done
[22:39] javajunky: mape: um, nope :)
[22:40] mjr_: he was also talking about doing it with http.client instead of net
[22:40] mjr_: weren't you?
[22:40] javajunky: I just need wanted to sort out oauth2 support in my oauth module, which I can now trivially do :) 
[22:40] javajunky: mjr_ … that is how I've done it ..isn't it ?
[22:40] mjr_: yes, but map uses net.createConnection
[22:41] mjr_: mape does, that is
[22:41] javajunky: ahh I see, yeah mape, my way is with the http client so no managing of that cruft (yay!) 
[22:41] javajunky: mjr_ <g> timing
[22:41] mape: hehe, easier to add headers and whatnot
[22:41] javajunky: mape: just less chance of me getting it wrong, not supporting some random aspect of http <g>
[22:44] javajunky: mape: did that mongo stuff work out ok for you ?
[22:44] mape: javajunky: yeah native worked fine
[22:44] javajunky: sweet.
[22:45] mape: the other one was wonky though
[22:45] javajunky: the native one seems to work pretty well tbh
[22:45] mape: guess the c binding is a tad faster then native javascipt implementation?
[22:45] mape: *script
[22:45] javajunky: one would assume so, but I'll take working but a little slower over not working at all any day ;)
[22:46] herbySk has joined the channel
[22:46] mape: hehe yeah
[22:46] mape: First time I looked at mongodb today
[22:46] mape: the APIs seem really neat
[22:46] devinus: ( listen, 0xFAB )
[22:46] devinus: wow.......
[22:48] mape: hehe
[22:48] plhw_: I wonder if anyone has come seen this behavior before. Im pretty sure its due to me not using node quite correctly but Im not sure. I have a http server which picks up requests and then has the response.write, response.end calls inside of an async call (to a db). When I hit the server in a browser the request just hangs. Anyone seen anything like this?
[22:48] mape: plhw_: paste the code in a bucket and link? :)
[22:49] plhw_: yeah...  one sec :]
[22:49] javajunky: mape: I wrote a small article a while back that uses some of the interfaces, may be a bit simple for you though: http://howtonode.org/express-mongodb
[22:49] javajunky: right I'm offski, nn
[22:49] devinus: does anybody know if i can use fab without all that crazy DSL shit
[22:49] devinus: ?
[22:49] mape: javajunky: later
[22:50] mape: devinus: Whats left then?
[22:50] javajunky: devinus: I thought the point of it was that it wasn't a dsl, it was all recursive function calls ?
[22:50] devinus: mape, javajunky: chained function calls that begin to lose readability after about 10 lines
[22:50] gf3 has joined the channel
[22:50] mape: devinus: then use express?
[22:51] javajunky: plhw_:  its almost a certainty that an error's being passed back up the callback chain and your response.write isn't being called ;) 
[22:51] mape: And I guess that is why you indent?
[22:51] javajunky: devinus: try something like expressjs.com , combined with one of the many concurrency apis such as step, flow, conductor (howtonode.org) ..
[22:51] javajunky: right I'm really offski
[22:51] plhw_: mape: http://pastebin.com/qkpBMxQm
[22:51] devinus: mape: nah, im using node-router. i just wanted to check out fab
[22:51] plhw_: javajunky: good thought, Ill try to see if thats whats up, thanks!
[22:53] plhw_: Not sure where I should be be attaching an error handler I guess..
[22:53] mape: plhw_: em
[22:53] isaacs has joined the channel
[22:54] mape: Not quite sure what that is, are you using a module to make it easier?
[22:54] plhw_: Im only using this cradle module to talk to couch
[22:54] isaacs has joined the channel
[22:54] plhw_: mape: otherwise its straight node i believe
[22:54] mape: Why 'foo' ?
[22:54] mape: And does the callback in cradle fire?
[22:54] plhw_: no reason but 'foo' never gets flushed out to the browser, it seems to hang 
[22:55] plhw_: the callback is supposed to return the results of the query 
[22:55] plhw_: so Id like to make a query and then when it finishes (and the callback is fired) return the results to the browser
[22:55] mape: but you are sure the callback fires?
[22:56] plhw_: Yeah thats the thing, I have no evidence that it does, If I put a sys.puts in there it never prints
[22:56] mape: Well then it doesn't
[22:56] mape: hence it never closes the request
[22:56] plhw_: that makes sense
[22:56] mape: And that makes it "hang"
[22:57] ssteinerX has joined the channel
[22:57] plhw_: but outside of that context (outside of the request handler function of the http server) it returns just fine
[22:57] mape: if you move the code inside the callback out of it that works ?
[22:57] mape: yeah
[22:57] plhw_: yeah if I move it out of the cb then it flushes out fine
[22:57] mape: So the cradleDb.view never run the callbakc
[22:58] mape: *ck
[22:58] plhw_: Right but if I move that query to before line 1, it completes properly and returns results
[22:58] plhw_: It seems like it only hangs when its inside that createServer context...
[22:58] plhw_: :\
[23:03] towski has joined the channel
[23:03] boaz has joined the channel
[23:05] pjb3 has joined the channel
[23:05] mattly has joined the channel
[23:07] byoteki has joined the channel
[23:07] bmizerany has joined the channel
[23:09] nwhite has joined the channel
[23:22] bmizeran_ has joined the channel
[23:23] Wandrewvious has joined the channel
[23:25] boaz has joined the channel
[23:35] jedschmidt has joined the channel
[23:38] dekz has joined the channel
[23:38] er1c_ has joined the channel
[23:42] ryan[WIN]: anyone ever done JSONP with node?
[23:43] bmizerany has joined the channel
[23:44] cruxst has joined the channel
[23:44] ryan[WIN]: i'm doing a JSONP wiht jquery
[23:44] ryan[WIN]: and i think node's query parser is buggin' out
[23:45] ryan[WIN]: http://proggit.pastebin.com/ekkeCXxa
[23:45] ryan[WIN]: when i do a sys.puts(sys.inspect(url.parse(req.url, parseQueryString=true)));
[23:46] ryan[WIN]: it doesn't parse the first param correctly
[23:47] ryan[WIN]: hm
[23:48] ryan[WIN]: nm i fixt it
